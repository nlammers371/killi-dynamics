{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from src.data_io.track_io import _load_track_data\n",
    "from src.tracking.track_processing import preprocess_tracks\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# --- parameters ---\n",
    "root = Path(r\"Y:\\killi_dynamics\")\n",
    "project_name = \"20251019_BC1-NLS_52-80hpf\"\n",
    "tracking_config = \"tracking_20251102\"\n",
    "\n",
    "# load cell tracks\n",
    "tracks_df_raw, sphere_df = _load_track_data(root=root,\n",
    "                                            project_name=project_name,\n",
    "                                            tracking_config=tracking_config,\n",
    "                                            prefer_smoothed=False)\n",
    "\n",
    "tracks_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean tracks\n",
    "To-do's:\n",
    "1. Add in confirmed nucleus masks that are dropped by tracking\n",
    "2. Re-integrate logic to fuse tracks that appear to be duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = 930 # filters for through to early aggregation stages\n",
    "track_class = np.asarray([0]) # deep cells only\n",
    "tracks_df = tracks_df_raw.rename(columns={\"mean_fluo\":\"BC1\"})\n",
    "# tracks_df = tracks_df[tracks_df['track_class'].isin(track_class)] \n",
    "tracks_df = tracks_df[tracks_df[\"t\"]<max_frame]\n",
    "\n",
    "tracks_df = preprocess_tracks(tracks_df)\n",
    "\n",
    "# go ahead and remove stationary tracks\n",
    "tracks_df = tracks_df[~tracks_df[\"track_mostly_stationary\"]]\n",
    "\n",
    "# calculate smoothed BC1 values\n",
    "tracks_df[\"BC1_sm\"] = (\n",
    "    tracks_df.groupby(\"track_id\")[\"BC1\"]\n",
    "             .rolling(window=3, center=True, min_periods=1)\n",
    "             .mean()\n",
    "             .reset_index(level=0, drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add smoothed tracks and calculate spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_sm, _ = _load_track_data(root=root,\n",
    "                                            project_name=project_name,\n",
    "                                            tracking_config=tracking_config,\n",
    "                                            prefer_smoothed=True)\n",
    "\n",
    "tracks_df_sm = tracks_df_sm.rename(columns={\"x\":\"xs\", \"y\":\"ys\", \"z\":\"zs\"})\n",
    "tracks_df = tracks_df.merge(tracks_df_sm.loc[:, [\"t\", \"track_id\", \"xs\", \"ys\", \"zs\"]], how=\"left\", on=[\"track_id\", \"t\"])\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell number over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count_table = tracks_df.groupby([\"t\", \"track_class\"]).count().reset_index()\n",
    "fig = px.line(cell_count_table, x=\"t\", y=\"track_id\", color=\"track_class\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a correlation between BC1 intensity and local cell density?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_surface_density(df, xcol=\"x\", ycol=\"y\", zcol=\"z\", \n",
    "                            groupcol=\"t\", k=10, min_points=5):\n",
    "    \"\"\"\n",
    "    Computes approximate local *surface* density for each cell at each timepoint.\n",
    "    Uses kNN search radius but divides by disk area (π r^2).\n",
    "    Units: 1 / length^2\n",
    "    \"\"\"\n",
    "    df = df.sort_values([groupcol]).reset_index(drop=True)\n",
    "    coords = df[[xcol, ycol, zcol]].to_numpy()\n",
    "    times = df[groupcol].to_numpy()\n",
    "    \n",
    "    density = np.full(len(df), np.nan)\n",
    "    \n",
    "    grouped = df.groupby(groupcol).groups  # dict: t -> row indices\n",
    "    \n",
    "    for t, idxs in tqdm(grouped.items(), desc=\"Calculating NN densities...\"):\n",
    "        idxs = np.array(idxs)\n",
    "\n",
    "        if len(idxs) < min_points:\n",
    "            continue\n",
    "\n",
    "        pts = coords[idxs]\n",
    "        tree = KDTree(pts)\n",
    "\n",
    "        # Query k+1 nearest since first entry is itself\n",
    "        dists, _ = tree.query(pts, k=k+1)\n",
    "        r_k = dists[:, -1]  # radius to k-th neighbor\n",
    "\n",
    "        # Avoid divide-by-zero\n",
    "        r_k[r_k == 0] = np.nan\n",
    "\n",
    "        # Surface area of local patch ~ π r^2\n",
    "        areas = np.pi * (r_k ** 2)\n",
    "\n",
    "        densities = k / areas  # units = 1 / length^2\n",
    "        density[idxs] = densities\n",
    "\n",
    "    return density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[\"nn_sa_density\"] = compute_surface_density(tracks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 15\n",
    "start_t = 850\n",
    "stop_t = 930\n",
    "\n",
    "time_filter = (tracks_df[\"t\"] > start_t) & (tracks_df[\"t\"] <= stop_t)\n",
    "plot_df = tracks_df.loc[time_filter].copy()\n",
    "\n",
    "# label bins nicely\n",
    "bin_labels = [f\"bin {i+1}\" for i in range(nbins)]\n",
    "\n",
    "# quantize BC1_sm\n",
    "plot_df[\"BC1_bin\"] = pd.qcut(\n",
    "    plot_df[\"BC1_sm\"],\n",
    "    q=nbins,\n",
    "    labels=False\n",
    ")\n",
    "\n",
    "bin_medians = (\n",
    "    plot_df.groupby(\"BC1_bin\")[\"BC1_sm\"]\n",
    "           .median()\n",
    "           .to_numpy()\n",
    ")\n",
    "\n",
    "bin_median_table = (\n",
    "    plot_df.groupby(\"BC1_bin\")[\"BC1_sm\"]\n",
    "           .median()\n",
    "           .reset_index(name=\"BC1_median\")\n",
    ")\n",
    "\n",
    "plot_df = plot_df.merge(bin_median_table, on=\"BC1_bin\", how=\"left\")\n",
    "plot_df = plot_df.loc[:, [\"BC1_bin\", \"BC1_median\", \"nn_sa_density\"]].groupby([\"BC1_bin\", \"BC1_median\"]).mean().reset_index() \n",
    "\n",
    "#fig = px.box(\n",
    "#    plot_df,\n",
    "#    x=\"BC1_bin\",\n",
    "#    y=\"nn_sa_density\",\n",
    "#    title=\"Surface density by BC1 intensity bin\",\n",
    "#    width=800,\n",
    "#    height=600,\n",
    "#    points=False\n",
    "#)\n",
    "fig = px.scatter(plot_df, x=\"BC1_median\", y=\"nn_sa_density\")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"BC1 intensity bin\",\n",
    "    yaxis_title=\"NN surface density\",\n",
    "    template=\"plotly_white\",\n",
    "    width=800, \n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### BC1 intensity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fig = px.histogram(tracks_df, x='BC1', nbins=100, title='BC1 mean intensity distribution')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fig = px.density_heatmap(\n",
    "#     tracks_df,\n",
    "#     x=\"t\",\n",
    "#     y=\"BC1\",\n",
    "#     nbinsx=15,\n",
    "#     nbinsy=15,\n",
    "#     color_continuous_scale=\"Viridis\"\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(tracks_df, x=\"t\", y=\"BC1\", title='BC1 mean intensity over time', opacity=0.5)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a link between bc1 and proliferation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get IDs of tracks that produced offpsring\n",
    "parent_table = tracks_df.loc[tracks_df[\"parent_track_id\"]>-1, [\"t\", \"parent_track_id\", \"track_id\"]].drop_duplicates()\n",
    "parent_table = parent_table.groupby([\"track_id\", \"parent_track_id\"]).min().reset_index().sort_values([\"t\", \"parent_track_id\"])\n",
    "\n",
    "# label tracks that produce offspring\n",
    "parent_ids = parent_table[\"parent_track_id\"].to_numpy()\n",
    "child_ids = parent_table[\"track_id\"].to_numpy()\n",
    "tracks_df.loc[:, \"parent_flag\"] = 0\n",
    "tracks_df.loc[:, \"child_flag\"] = 0\n",
    "tracks_df.loc[tracks_df[\"track_id\"].isin(parent_ids), \"parent_flag\"] = 1\n",
    "tracks_df.loc[tracks_df[\"track_id\"].isin(parent_ids), \"child_flag\"] = 1\n",
    "tracks_df[\"proliferative_flag\"] = tracks_df[\"child_flag\"] | tracks_df[\"parent_flag\"]\n",
    "\n",
    "# check consistency\n",
    "# print(len(tracks_df.loc[tracks_df[\"parent_flag\"]==1, \"track_id\"].unique()))\n",
    "# print(len(parent_table[\"parent_track_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_track_df = tracks_df.loc[tracks_df[\"parent_flag\"]==1]\n",
    "div_df = (\n",
    "    parent_track_df.sort_values([\"track_id\", \"t\", \"x\", \"y\", \"z\"])\n",
    "             .groupby(\"track_id\")\n",
    "             .tail(1)\n",
    ")\n",
    "\n",
    "fig = px.scatter_3d(div_df.loc[div_df[\"t\"]>500], x=\"x\", y=\"y\", z=\"z\", color=\"t\", opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prolif_df = tracks_df.loc[tracks_df[\"parent_track_id\"]>-1, [\"t\", \"parent_track_id\"]].drop_duplicates()\n",
    "prolif_df = prolif_df.groupby([\"parent_track_id\"]).min().reset_index().sort_values([\"t\", \"parent_track_id\"])\n",
    "prolif_df = prolif_df.loc[:, [\"t\",\"parent_track_id\"]].drop_duplicates().groupby(\"t\").count().reset_index().rename(columns={\"parent_track_id\":\"dN\"})\n",
    "\n",
    "prolif_df[\"N\"] = 888 + prolif_df[\"dN\"].cumsum()\n",
    "\n",
    "fig = px.line(prolif_df, x=\"t\", y=\"N\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tids = np.unique(tracks_df.loc[tracks_df[\"parent_track_id\"]>-1, [\"parent_track_id\"]])\n",
    "tids = np.unique(tracks_df.loc[:, [\"track_id\"]])\n",
    "tids_raw = np.unique(tracks_df_raw.loc[:, [\"track_id\"]])\n",
    "print(len(p_tids))\n",
    "print(np.sum(np.isin(p_tids, tids)))\n",
    "print(np.sum(np.isin(p_tids, tids_raw)))\n",
    "# fig = px.histogram(parent_table, x='t', nbins=25, title='Division times')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# time bins\n",
    "nbins = 5\n",
    "time_bins = np.linspace(100, 900, nbins+1)\n",
    "\n",
    "# get last obs prior to division for parents\n",
    "parent_track_df = tracks_df.loc[tracks_df[\"parent_flag\"]==1]\n",
    "pre_div_df = (\n",
    "    parent_track_df.sort_values([\"track_id\", \"t\"])\n",
    "             .groupby(\"track_id\")\n",
    "             .tail(10)\n",
    ")\n",
    "\n",
    "child_track_df = tracks_df.loc[tracks_df[\"child_flag\"]==1]\n",
    "post_div_df = (\n",
    "    parent_track_df.sort_values([\"track_id\", \"t\"])\n",
    "             .groupby(\"track_id\")\n",
    "             .head(10)\n",
    ")\n",
    "\n",
    "\n",
    "# generate our null\n",
    "null_df = tracks_df.loc[tracks_df[\"proliferative_flag\"]==0]\n",
    "pre_null_df = (\n",
    "     null_df.sort_values([\"track_id\", \"t\"])\n",
    "             .groupby(\"track_id\")\n",
    "             .head(10)\n",
    ")\n",
    "post_null_df = (\n",
    "     null_df.sort_values([\"track_id\", \"t\"])\n",
    "             .groupby(\"track_id\")\n",
    "             .tail(10)\n",
    ")\n",
    "\n",
    "null_df = pd.concat([pre_null_df, post_null_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "\n",
    "def bootstrap_rolling_mean(df, xcol, ycol, window=51, B=200):\n",
    "    \"\"\"\n",
    "    Computes:\n",
    "      - rolling mean (centered)\n",
    "      - bootstrap CI for the rolling mean\n",
    "\n",
    "    df must contain xcol and ycol.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort once\n",
    "    df = df[[xcol, ycol]].dropna().sort_values(xcol).reset_index(drop=True)\n",
    "\n",
    "    x = df[xcol].to_numpy()\n",
    "    y = df[ycol].to_numpy()\n",
    "\n",
    "    # Base rolling mean\n",
    "    mean = pd.Series(y).rolling(window, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "    # Collect bootstrap smooths\n",
    "    boot = np.zeros((B, len(y)))\n",
    "\n",
    "    for b in range(B):\n",
    "        resample = df.sample(len(df), replace=True)\n",
    "\n",
    "        # Sort the bootstrap sample so smoothing makes sense\n",
    "        resample = resample.sort_values(xcol)\n",
    "        yb = resample[ycol].to_numpy()\n",
    "\n",
    "        boot[b] = (\n",
    "            pd.Series(yb)\n",
    "              .rolling(window, center=True, min_periods=1)\n",
    "              .mean()\n",
    "              .to_numpy()\n",
    "        )\n",
    "\n",
    "    # Compute percentile CI\n",
    "    lower = np.nanpercentile(boot, 2.5, axis=0)\n",
    "    upper = np.nanpercentile(boot, 97.5, axis=0)\n",
    "\n",
    "    # Output dataframe\n",
    "    out = pd.DataFrame({\n",
    "        xcol: x,\n",
    "        \"mean\": mean,\n",
    "        \"low\":  lower,\n",
    "        \"high\": upper\n",
    "    })\n",
    "\n",
    "    return out.dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# pos_smooth  = bootstrap_rolling_mean(pre_div_df,  \"t\", \"BC1_sm\", window=11, B=200)\n",
    "# null_smooth = bootstrap_rolling_mean(pre_null_df, \"t\", \"BC1_sm\", window=11, B=200)\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "# # Parent\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=pos_smooth[\"t\"],\n",
    "#     y=pos_smooth[\"mean\"],\n",
    "#     mode=\"lines\",\n",
    "#     line=dict(color=\"red\"),\n",
    "#     name=\"Parent (mean)\"\n",
    "# ))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=pd.concat([pos_smooth[\"t\"], pos_smooth[\"t\"][::-1]]),\n",
    "#     y=pd.concat([pos_smooth[\"high\"], pos_smooth[\"low\"][::-1]]),\n",
    "#     fill='toself',\n",
    "#     fillcolor='rgba(255,0,0,0.25)',\n",
    "#     line=dict(color=\"rgba(255,0,0,0)\"),\n",
    "#     showlegend=False\n",
    "# ))\n",
    "\n",
    "# # Null\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=null_smooth[\"t\"],\n",
    "#     y=null_smooth[\"mean\"],\n",
    "#     mode=\"lines\",\n",
    "#     line=dict(color=\"blue\"),\n",
    "#     name=\"Null (mean)\"\n",
    "# ))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=pd.concat([null_smooth[\"t\"], null_smooth[\"t\"][::-1]]),\n",
    "#     y=pd.concat([null_smooth[\"high\"], null_smooth[\"low\"][::-1]]),\n",
    "#     fill='toself',\n",
    "#     fillcolor='rgba(0,0,255,0.25)',\n",
    "#     line=dict(color=\"rgba(0,0,255,0)\"),\n",
    "#     showlegend=False\n",
    "# ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=\"Bootstrap Rolling Mean with CI\",\n",
    "#     xaxis_title=\"Time (t)\",\n",
    "#     yaxis_title=\"BC1_sm\",\n",
    "#     template=\"plotly_white\"\n",
    "# )\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time bins\n",
    "nbins = 5\n",
    "time_bins = np.linspace(100, 900, nbins + 1)\n",
    "\n",
    "# label bins nicely\n",
    "bin_labels = [f\"bin {i+1}\" for i in range(nbins)]\n",
    "\n",
    "pre_div_df[\"time_bin\"] = pd.cut(\n",
    "    pre_div_df[\"t\"], bins=time_bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "post_div_df[\"time_bin\"] = pd.cut(\n",
    "    post_div_df[\"t\"], bins=time_bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "null_df[\"time_bin\"] = pd.cut(\n",
    "    null_df[\"t\"], bins=time_bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(\n",
    "    pd.concat([\n",
    "        pre_div_df.assign(group=\"Parent\"),\n",
    "        post_div_df.assign(group=\"Child\"),\n",
    "        null_df.assign(group=\"Null\")\n",
    "    ]),\n",
    "    x=\"time_bin\",\n",
    "    y=\"BC1_sm\",\n",
    "    color=\"group\",\n",
    "    points=\"outliers\",   # or \"all\" or False\n",
    "    title=\"BC1_sm by time bin\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Time bin\",\n",
    "    yaxis_title=\"BC1_sm\",\n",
    "    boxmode=\"group\",   # group parent & null side-by-side\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:31:30.001595200Z",
     "start_time": "2025-11-14T22:31:29.874232700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Basic track plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_tracklets(\n",
    "    tracks_df: pd.DataFrame,\n",
    "    deltaT: int,\n",
    "    stride: int,\n",
    "    fluo_col: str = \"gene_level\",\n",
    "):\n",
    "    long_rows = []     # long-format rows (one per timepoint)\n",
    "    summary_rows = []  # one per tracklet\n",
    "\n",
    "    for tid, g in tqdm(tracks_df.groupby(\"track_id\"), desc=\"Generating tracklets...\"):\n",
    "        g = g.sort_values(\"t\").reset_index(drop=True)\n",
    "\n",
    "        t = g[\"t\"].to_numpy()\n",
    "        fl = g[fluo_col].to_numpy()\n",
    "\n",
    "        x_arr = g[\"x\"].to_numpy()\n",
    "        y_arr = g[\"y\"].to_numpy()\n",
    "        z_arr = g[\"z\"].to_numpy()\n",
    "\n",
    "        # slide window over actual time values\n",
    "        tmin, tmax = t.min(), t.max()\n",
    "\n",
    "        for t0 in range(tmin, tmax - deltaT + 1, stride):\n",
    "            t1 = t0 + deltaT\n",
    "\n",
    "            mask = (t >= t0) & (t < t1)\n",
    "            idx = np.where(mask)[0]\n",
    "\n",
    "            # require exact deltaT frames in window\n",
    "            if len(idx) != deltaT:\n",
    "                continue\n",
    "\n",
    "            # create new tracklet id\n",
    "            tracklet_id = len(summary_rows)\n",
    "\n",
    "            # ---- (1) Append long-format rows ----\n",
    "            for ii in idx:\n",
    "                long_rows.append({\n",
    "                    \"tracklet_id\": tracklet_id,\n",
    "                    \"parent_track_id\": tid,\n",
    "                    \"t\": int(t[ii]),\n",
    "                    \"x\": float(x_arr[ii]),\n",
    "                    \"y\": float(y_arr[ii]),\n",
    "                    \"z\": float(z_arr[ii]),\n",
    "                    fluo_col: float(fl[ii]),\n",
    "                })\n",
    "\n",
    "            # ---- (2) Append summary row ----\n",
    "            summary_rows.append({\n",
    "                \"tracklet_id\": tracklet_id,\n",
    "                \"parent_track_id\": tid,\n",
    "                \"t_start\": t0,\n",
    "                \"t_end\": t1,\n",
    "                fluo_col: float(fl[idx].mean()),\n",
    "                # (optional: mean positions)\n",
    "                # \"mean_x\": float(x_arr[idx].mean()),\n",
    "                # \"mean_y\": float(y_arr[idx].mean()),\n",
    "                # \"mean_z\": float(z_arr[idx].mean()),\n",
    "            })\n",
    "\n",
    "    long_df = pd.DataFrame(long_rows)\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    return long_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dT = int(60*60 / 90)\n",
    "stride = dT // 2 + 1\n",
    "\n",
    "tracklets_long, tracklet_summary = make_tracklets(tracks_df, deltaT=dT, stride=stride, fluo_col=\"BC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(tracklet_summary, x=\"t_start\", y=\"mean_fluo\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklets_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 25\n",
    "time_filter = (tracklet_summary[\"t_end\"] < 930) & (tracklet_summary[\"t_end\"] > 800)\n",
    "high_filter = tracklet_summary[\"mean_fluo\"] > 400\n",
    "low_filter = (tracklet_summary[\"mean_fluo\"] > 150) & (tracklet_summary[\"mean_fluo\"] < 250)\n",
    "bright_tracks = tracklet_summary.loc[time_filter & high_filter, \"tracklet_id\"].to_numpy()\n",
    "dim_tracks = tracklet_summary.loc[time_filter & low_filter, \"tracklet_id\"].to_numpy()\n",
    "\n",
    "# choose candidages\n",
    "dim_ids = np.random.choice(dim_tracks, n_samples, replace=False)\n",
    "bright_ids = np.random.choice(bright_tracks, n_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_tracklets = tracklets_long[tracklets_long[\"tracklet_id\"].isin(dim_ids)].copy()\n",
    "dim_tracklets[[\"xc\",\"yc\",\"zc\"]] = (\n",
    "    dim_tracklets[[\"x\",\"y\",\"z\"]] -\n",
    "    dim_tracklets.groupby(\"tracklet_id\")[[\"x\",\"y\",\"z\"]].transform(\"first\")\n",
    ")\n",
    "\n",
    "bright_tracklets = tracklets_long[tracklets_long[\"tracklet_id\"].isin(bright_ids)].copy()\n",
    "bright_tracklets[[\"xc\",\"yc\",\"zc\"]] = (\n",
    "    bright_tracklets[[\"x\",\"y\",\"z\"]] -\n",
    "    bright_tracklets.groupby(\"tracklet_id\")[[\"x\",\"y\",\"z\"]].transform(\"first\")\n",
    ")\n",
    "bright_tracklets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "x=\"xc\"\n",
    "y=\"yc\"\n",
    "z=\"zc\"\n",
    "df = bright_tracklets\n",
    "\n",
    "palette = px.colors.qualitative.Plotly # or Set3, Plotly, Alphabet, etc.\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "tracklets = df[\"tracklet_id\"].unique()\n",
    "n_colors = len(palette)\n",
    "\n",
    "for i, tid in enumerate(tracklets):\n",
    "    g = df[df[\"tracklet_id\"] == tid]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=g[x],\n",
    "            y=g[y],\n",
    "            z=g[z],\n",
    "            mode=\"lines\",\n",
    "            name=str(tid),\n",
    "            line=dict(\n",
    "                width=3,\n",
    "                color=palette[i % n_colors]   # categorical color\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=y,\n",
    "        zaxis_title=z,\n",
    "    ),\n",
    "    legend_title_text=\"tracklet_id\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at basic speed and velocity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def add_short_scale_metrics(df, scale_short, dt, track_col=\"track_id\"):\n",
    "    \"\"\"\n",
    "    Fastest implementation without numba.\n",
    "    Uses stride tricks to compute per-timepoint rolling contour-length speed\n",
    "    and rolling net velocity in vectorized numpy form.\n",
    "\n",
    "    Assumes tracks have contiguous rows in time (no duplicates, sorted).\n",
    "    Does NOT assume contiguous t values — just contiguity in the dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"v_path_short\"] = np.nan\n",
    "    df[\"v_net_short_x\"] = np.nan\n",
    "    df[\"v_net_short_y\"] = np.nan\n",
    "    df[\"v_net_short_z\"] = np.nan\n",
    "    df[\"v_net_short_mag\"] = np.nan\n",
    "\n",
    "    half = scale_short // 2\n",
    "\n",
    "    for tid, g in tqdm(df.groupby(track_col), desc=\"Calculating velocity metrics...\"):\n",
    "        g = g.sort_values(\"t\")\n",
    "        idx = g.index.to_numpy()\n",
    "\n",
    "        x = g[\"x\"].to_numpy()\n",
    "        y = g[\"y\"].to_numpy()\n",
    "        z = g[\"z\"].to_numpy()\n",
    "\n",
    "        # ---------- STEP-LENGTHS ----------\n",
    "        dx = np.diff(x)\n",
    "        dy = np.diff(y)\n",
    "        dz = np.diff(z)\n",
    "        steps = np.sqrt(dx*dx + dy*dy + dz*dz)  # shape (n-1,)\n",
    "\n",
    "        n = len(g)\n",
    "\n",
    "        # ---------- ROLLING STEP WINDOWS ----------\n",
    "        # For each center position i, step window = steps[(i-half):(i+half)]\n",
    "        # Get indices of step windows\n",
    "        lefts = np.arange(n) - half\n",
    "        rights = np.arange(n) + half\n",
    "\n",
    "        # Clip to valid range, but mark invalid windows\n",
    "        valid = (lefts >= 0) & (rights < n)\n",
    "        lefts = np.clip(lefts, 0, n-2)\n",
    "        rights = np.clip(rights, 1, n-1)\n",
    "\n",
    "        # Build step windows using sliding_window_view\n",
    "        # steps_w shape: (n-1 - (window_size-1), window_size) but we select rows we need\n",
    "        window_size = scale_short - 1  # number of steps in window\n",
    "        if window_size <= 0:\n",
    "            continue\n",
    "\n",
    "        if len(steps) >= window_size:\n",
    "            steps_w = sliding_window_view(steps, window_shape=window_size)\n",
    "        else:\n",
    "            steps_w = None\n",
    "\n",
    "        v_path = np.full(n, np.nan)\n",
    "\n",
    "        # Only fill valid positions\n",
    "        valid_idx = np.where(valid)[0]\n",
    "        if steps_w is not None:\n",
    "            # Map each center index to the corresponding steps window row\n",
    "            # row index = lefts[i]\n",
    "            rows = lefts[valid_idx]\n",
    "            step_sums = steps_w[rows].sum(axis=1)  # vectorized sum\n",
    "            durations = window_size * dt\n",
    "            v_path[valid_idx] = step_sums / durations\n",
    "\n",
    "        # ---------- NET VELOCITY ----------\n",
    "        v_net_x = np.full(n, np.nan)\n",
    "        v_net_y = np.full(n, np.nan)\n",
    "        v_net_z = np.full(n, np.nan)\n",
    "\n",
    "        # dx, dy, dz across window\n",
    "        dx_net = x[rights] - x[lefts]\n",
    "        dy_net = y[rights] - y[lefts]\n",
    "        dz_net = z[rights] - z[lefts]\n",
    "\n",
    "        v_net_x[valid] = dx_net[valid] / ((scale_short - 1) * dt)\n",
    "        v_net_y[valid] = dy_net[valid] / ((scale_short - 1) * dt)\n",
    "        v_net_z[valid] = dz_net[valid] / ((scale_short - 1) * dt)\n",
    "\n",
    "        # store outputs\n",
    "        df.loc[idx, \"v_path_short\"] = v_path\n",
    "        df.loc[idx, \"v_net_short_x\"] = v_net_x\n",
    "        df.loc[idx, \"v_net_short_y\"] = v_net_y\n",
    "        df.loc[idx, \"v_net_short_z\"] = v_net_z\n",
    "        df.loc[idx, \"v_net_short_mag\"] = np.sqrt(v_net_x**2 + v_net_y**2 + v_net_z**2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_vel = add_short_scale_metrics(tracks_df, \n",
    "                                        scale_short=7,\n",
    "                                        dt=1.5)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filter = (tracks_df_vel[\"t\"] < 930) & (tracks_df_vel[\"t\"] > 800)\n",
    "bc1_filter = (tracks_df_vel[\"BC1\"] > 150) \n",
    "\n",
    "tracks_df_vel[\"vi\"] = np.divide(tracks_df_vel[\"v_path_short\"], tracks_df_vel[\"v_net_short_mag\"]).copy()\n",
    "tracks_plot = tracks_df_vel.loc[time_filter & bc1_filter]\n",
    "tracks_plot[\"fluo_bin\"] = pd.qcut(tracks_plot[\"BC1\"], q=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    tracks_plot,\n",
    "    x=\"fluo_bin\",\n",
    "    y=\"vi\",\n",
    "    points=False,      # no individual dots\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"BC1 bin (quantiles)\",\n",
    "    yaxis_title=\"speed\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

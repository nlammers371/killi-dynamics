{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from compile_sweep_results import compile_sweep_results\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "root = Path(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/symmetry_breaking/sweep_results/\")\n",
    "sweep_name = \"sweep06_field_tuning\"\n",
    "output_dir = root / sweep_name\n",
    "fig_path = Path(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/killifish/20250815/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for path in tqdm(output_dir.glob(\"*.json\")):\n",
    "    # First try pandas' JSON reader for Series format\n",
    "    s = pd.read_json(path, typ=\"series\")\n",
    "    s = s.copy()\n",
    "    s[\"__source_file__\"] = path.name\n",
    "    s[\"sim_id\"] = s[\"__source_file__\"].replace(\"result_\", \"\").replace(\".json\", \"\")\n",
    "    rows.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Compile results into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_cols = [\"Activator\", \"Repressor\", \"rho\"]\n",
    "skip_cols = [\"x\", \"times\"] + array_cols\n",
    "param_cols = [col for col in rows[0].keys() if col not in [\"sim_id\"] + skip_cols]\n",
    "param_cols = [\"sim_id\"] + param_cols\n",
    "\n",
    "x_grid = (np.asarray(rows[0][\"x\"]) - 1500)[:, None]\n",
    "t_grid = np.asarray(rows[0][\"times\"])[:, None]\n",
    "x_cols = [f\"x{i:04}\" for i in range(len(x_grid))]\n",
    "\n",
    "param_dfs = []\n",
    "activator_dfs = []\n",
    "repressor_dfs = []\n",
    "rho_dfs = []\n",
    "skipped = 0\n",
    "# iterate\n",
    "for row in tqdm(rows):\n",
    "\n",
    "    # params\n",
    "    p_temp = pd.DataFrame(row[param_cols])\n",
    "    param_dfs.append(p_temp.T)\n",
    "    # try:\n",
    "    t_vec = np.asarray(row[\"times\"])[:, None]\n",
    "    sim_id_vec = np.tile(row[\"sim_id\"], len(t_vec))[:, None]\n",
    "    # N df\n",
    "    a_array = np.asarray(row[\"Activator\"])\n",
    "    a_temp = pd.DataFrame(np.c_[sim_id_vec, t_vec, a_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "    activator_dfs.append(a_temp)\n",
    "    # L df\n",
    "    r_array = np.asarray(row[\"Repressor\"])\n",
    "    r_temp = pd.DataFrame(np.c_[sim_id_vec, t_vec, r_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "    repressor_dfs.append(r_temp)\n",
    "    # rho df\n",
    "    rho_array = np.asarray(row[\"rho\"])\n",
    "    rho_temp = pd.DataFrame(np.c_[sim_id_vec, t_vec, rho_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "    rho_dfs.append(rho_temp)\n",
    "# except:\n",
    "    skipped += 1\n",
    "\n",
    "\n",
    "Nodal_df = pd.concat(activator_dfs, axis=0, ignore_index=True)\n",
    "Lefty_df = pd.concat(repressor_dfs, axis=0, ignore_index=True)\n",
    "rho_df = pd.concat(rho_dfs, axis=0, ignore_index=True)\n",
    "param_df = pd.concat(param_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "Nodal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Count Nodal peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_N = 10\n",
    "sigma_L = 10\n",
    "mu_L = 0.0002275846\n",
    "mu_N = mu_L * 1.11e-4/0.61e-4\n",
    "\n",
    "N_factor = sigma_N / mu_N\n",
    "L_factor = sigma_L / mu_L\n",
    "\n",
    "# target domain sigma: 250\n",
    "d_sigma = 250\n",
    "ref_grid = x_grid.ravel()\n",
    "# generate calculation masks\n",
    "mid_mask = np.abs(ref_grid) <= d_sigma\n",
    "left_mask = ref_grid < -d_sigma\n",
    "right_mask = ref_grid > d_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symmetry_breaking.utilities.helpers import count_nodal_peaks_periodic\n",
    "T_min = 35000\n",
    "# get last entris\n",
    "Nodal_df[\"t\"] = Nodal_df[\"t\"].astype(float)\n",
    "last_nodal_df = Nodal_df.loc[Nodal_df[\"t\"]>=T_min].drop_duplicates(subset=[\"sim_id\"], keep=\"last\")\n",
    "# last_nodal_df = Nodal_df.groupby(\"sim_id\").last().reset_index()\n",
    "# keep only those that ran to completion\n",
    "# T_min = 35000\n",
    "# last_nodal_df[\"t\"] = last_nodal_df[\"t\"].values.astype(float)\n",
    "# last_nodal_df = last_nodal_df.loc[last_nodal_df[\"t\"]>=T_min, :]\n",
    "last_nodal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_peak_vec = []\n",
    "peak_pos_vec = []\n",
    "\n",
    "h_thresh = 10000\n",
    "k_thresh = 5000\n",
    "for sim_id in tqdm(last_nodal_df[\"sim_id\"]):\n",
    "\n",
    "    # get nodal\n",
    "    nodal_vec = last_nodal_df.loc[last_nodal_df[\"sim_id\"]==sim_id, x_cols].to_numpy()[0].astype(float)\n",
    "\n",
    "    # count \n",
    "    peaks = count_nodal_peaks_periodic(nodal_vec, height_thresh=h_thresh, k_prom=k_thresh)\n",
    "\n",
    "    n_peak_vec.append(peaks[0])\n",
    "    peak_pos_vec.append(peaks[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(last_nodal_df[\"sim_id\"].copy())\n",
    "temp_df[\"n_peaks\"] = n_peak_vec\n",
    "pattern_df = param_df.merge(temp_df, how=\"inner\", on=\"sim_id\")\n",
    "pattern_df[\"tau_N\"] = pattern_df[\"rate_N\"].astype(float)**-1 / 3600\n",
    "pattern_df[\"D_L\"] = pattern_df[\"D_L\"].astype(\"float\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from src.utilities.plot_functions import format_2d_plotly\n",
    "import os\n",
    "\n",
    "# Choose your continuous colormap\n",
    "SCALE = px.colors.sequential.Viridis  # or Plasma, Cividis, Magma, etc.\n",
    "REVERSE = False                       # set True to invert\n",
    "\n",
    "# Compute D_L range for normalization\n",
    "dl_vals = pattern_df[\"D_L\"].astype(float)\n",
    "dl_min, dl_max = float(dl_vals.min()), float(dl_vals.max())\n",
    "\n",
    "def color_for_dl(v):\n",
    "    # normalize to [0,1]\n",
    "    if dl_max == dl_min:\n",
    "        t = 0.5\n",
    "    else:\n",
    "        t = (float(v) - dl_min) / (dl_max - dl_min)\n",
    "    if REVERSE:\n",
    "        t = 1.0 - t\n",
    "    # sample from the colorscale\n",
    "    return px.colors.sample_colorscale(SCALE, [t])[0]\n",
    "\n",
    "# 1) Base scatter with continuous color + colorbar\n",
    "fig = px.scatter(\n",
    "    pattern_df,\n",
    "    x=\"tau_N\", y=\"n_peaks\",\n",
    "    color=\"D_L\",\n",
    "    color_continuous_scale=SCALE if not REVERSE else SCALE[::-1],\n",
    "    log_x=True\n",
    ")\n",
    "\n",
    "# 2) Add smoothed line per unique D_L (log-x fit)\n",
    "for dl, gdf in pattern_df.groupby(\"D_L\"):\n",
    "    gdf = gdf.dropna(subset=[\"tau_N\", \"n_peaks\"])\n",
    "    if len(gdf) < 3:\n",
    "        continue  # need a few points to smooth\n",
    "    log_x = np.log10(gdf[\"tau_N\"].values)\n",
    "    y     = gdf[\"n_peaks\"].values\n",
    "\n",
    "    smoothed = lowess(y, log_x, frac=0.3, it=0, return_sorted=True)\n",
    "    smooth_x = 10**smoothed[:, 0]\n",
    "    smooth_y = smoothed[:, 1]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=smooth_x, y=smooth_y,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color_for_dl(dl), width=3),\n",
    "            name=f\"D_L={dl} trend\",\n",
    "            showlegend=False,           # avoid duplicate legend entries\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# (Optional) put lines behind markers\n",
    "# fig.data = tuple([tr for tr in fig.data if tr.mode == \"lines\"] +\n",
    "#                  [tr for tr in fig.data if tr.mode == \"markers\"])\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_colorbar=dict(\n",
    "        title=dict(\n",
    "            text=\"Lefty Diffusion Coefficient (μm²/s)\",\n",
    "            side=\"right\"        # or \"top\", \"bottom\", \"left\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=[\"trigger timescale\", \"number of aggregates\"], marker_size=6, font_size=16)\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(os.path.join(fig_path, \"N_agg_plot.png\"), scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(pattern_df.loc[pattern_df[\"N_amp\"]<10], x=\"N_delta\", y=\"L_center\", color=\"t\", hover_data={\"sim_id\"})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic_2d\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "def compute_flux_grid(df, grid_size=250, log=False, interp_res=250, \n",
    "                      id_col = \"sim_id\",\n",
    "                      x_col = \"N_delta_n\",\n",
    "                      y_col = \"L_center_n\"):\n",
    "    \"\"\"\n",
    "    Compute a dense interpolated flux field for streamplot from simulation trajectories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must have columns: sim_id, t, N_delta, L_center\n",
    "    grid_size : int\n",
    "        Number of bins for coarse binning before interpolation.\n",
    "    log : bool\n",
    "        If True, bin in log10 space for both axes.\n",
    "    interp_res : int\n",
    "        Resolution of final interpolated grid for plotting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xi, Yi : 2D arrays\n",
    "        Meshgrid coordinates (uniform spacing).\n",
    "    Ui, Vi : 2D arrays\n",
    "        Interpolated vector field components.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # id_col = \"sim_id\"\n",
    "    # x_col = \"N_delta_n\"\n",
    "    # y_col = \"L_center_n\"\n",
    "\n",
    "    # Compute per-step deltas\n",
    "    df[\"dx\"] = df.groupby(id_col)[x_col].shift(-1) - df[x_col]\n",
    "    df[\"dy\"] = df.groupby(id_col)[y_col].shift(-1) - df[y_col]\n",
    "    df = df.dropna(subset=[\"dx\", \"dy\"])\n",
    "\n",
    "    # Choose coordinates\n",
    "    if log:\n",
    "        Xdata = np.log10(df[x_col].to_numpy())\n",
    "        Ydata = np.log10(df[y_col].to_numpy())\n",
    "    else:\n",
    "        Xdata = df[x_col].to_numpy()\n",
    "        Ydata = df[y_col].to_numpy()\n",
    "\n",
    "    Udata = df[\"dx\"].to_numpy()\n",
    "    Vdata = df[\"dy\"].to_numpy()\n",
    "\n",
    "    # Coarse bin edges\n",
    "    xbins = np.linspace(Xdata.min(), Xdata.max(), grid_size)\n",
    "    ybins = np.linspace(Ydata.min(), Ydata.max(), grid_size)\n",
    "\n",
    "    # Bin-averaged velocity components\n",
    "    U_avg, _, _, _ = binned_statistic_2d(Xdata, Ydata, Udata, statistic='mean', bins=[xbins, ybins])\n",
    "    V_avg, _, _, _ = binned_statistic_2d(Xdata, Ydata, Vdata, statistic='mean', bins=[xbins, ybins])\n",
    "\n",
    "    U_avg = U_avg.T\n",
    "    V_avg = V_avg.T\n",
    "    \n",
    "    # Bin centers\n",
    "    x_centers = 0.5 * (xbins[:-1] + xbins[1:])\n",
    "    y_centers = 0.5 * (ybins[:-1] + ybins[1:])\n",
    "    Xc, Yc = np.meshgrid(x_centers, y_centers, indexing=\"xy\")\n",
    "\n",
    "    # Prepare valid points for interpolation\n",
    "    mask = ~np.isnan(U_avg) & ~np.isnan(V_avg)\n",
    "    points = np.column_stack((Xc[mask], Yc[mask]))\n",
    "    Uvals = U_avg[mask]\n",
    "    Vvals = V_avg[mask]\n",
    "\n",
    "    # Dense uniform interpolation grid\n",
    "    Xi = np.linspace(Xdata.min(), Xdata.max(), interp_res)\n",
    "    Yi = np.linspace(Ydata.min(), Ydata.max(), interp_res)\n",
    "    Xi, Yi = np.meshgrid(Xi, Yi, indexing=\"xy\")\n",
    "\n",
    "    Ui = griddata(points, Uvals, (Xi, Yi), method='linear', fill_value=0)\n",
    "    Vi = griddata(points, Vvals, (Xi, Yi), method='linear', fill_value=0)\n",
    "\n",
    "    return Xi, Yi, Ui, Vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "X, Y, U, V = compute_flux_grid(pattern_df, grid_size=100, log=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plot_indices = np.random.choice(3125, n_plot)\n",
    "x_col = \"N_delta_n\"\n",
    "y_col = \"L_center_n\"\n",
    "\n",
    "_, t_rank = np.unique(pattern_df[\"t\"], return_inverse=True)\n",
    "pattern_df[\"t_int\"] = t_rank\n",
    "t_filter = pattern_df[\"t_int\"] < 10\n",
    "x_t = pattern_df.loc[t_filter, x_col].to_numpy()[plot_indices]\n",
    "y_t = pattern_df.loc[t_filter, y_col].to_numpy()[plot_indices]\n",
    "\n",
    "speed = np.sqrt(U**2 + V**2)\n",
    "\n",
    "# Make the plot\n",
    "with plt.style.context(\"dark_background\"):\n",
    "    \n",
    "    # cmap = mpl.cm.get_cmap('inferno')\n",
    "    # cmap_trunc = mpl.colors.ListedColormap(cmap(np.linspace(0, 0.8, 256)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    strm = ax.streamplot(\n",
    "        X, Y, U, V,\n",
    "        color=\"white\",\n",
    "        density=2\n",
    "    )\n",
    "    \n",
    "    # Scatter overlay\n",
    "    # ax.scatter(x_t, y_t, color='black', edgecolor='k', zorder=3, label='t points')\n",
    "    \n",
    "    # Axis labels & title\n",
    "    ax.set_xlabel(\"Relative Nodal concentration ($[N_c]$-$[N_p]$)\")\n",
    "    ax.set_ylabel(\"Central Lefty concentration ($L_c$)\")\n",
    "    ax.set_title(\"Patterning phase space\")\n",
    "    \n",
    "    # Colorbar for velocity\n",
    "    # cbar = fig.colorbar(strm.lines, ax=ax, label=\"Speed\")\n",
    "    # plt.style.use(\"dark_background\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(fig_path / \"survival_phase_diagram.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "np.random.seed(137)\n",
    "frame_folder = fig_path / \"phase_frames\"\n",
    "os.makedirs(frame_folder, exist_ok=True)\n",
    "\n",
    "n_plot = 1500\n",
    "ui, ni = np.unique(pattern_df[\"sim_id\"], return_counts=True)\n",
    "good_ids = ui[ni==121]\n",
    "\n",
    "x0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, x_col]\n",
    "y0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, y_col]\n",
    "s0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, \"sim_id\"]\n",
    "high_ids = s0[(x0>=0.01) & (y0>=0.01)]\n",
    "\n",
    "# len(good_ids)\n",
    "# options = np.where(pattern_df[\"sim_id\"].isin(good_ids))[0]\n",
    "plot_ids = np.random.choice(good_ids, n_plot)\n",
    "id_filter = pattern_df[\"sim_id\"].isin(plot_ids) & pattern_df[\"sim_id\"].isin(high_ids)\n",
    "\n",
    "for t in tqdm(pattern_df[\"t_int\"].unique()):\n",
    "    \n",
    "    t_filter = (pattern_df[\"t_int\"] == t) & id_filter\n",
    "    x_t = pattern_df.loc[t_filter, x_col].to_numpy()\n",
    "    y_t = pattern_df.loc[t_filter, y_col].to_numpy()\n",
    "    \n",
    "    speed = np.sqrt(U**2 + V**2)\n",
    "    \n",
    "    # Make the plot\n",
    "    with plt.style.context(\"dark_background\"):\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        strm = ax.streamplot(\n",
    "            X, Y, U, V,\n",
    "            color=\"white\",\n",
    "            # cmap='viridis',\n",
    "            density=2\n",
    "        )\n",
    "        \n",
    "        # Scatter overlay\n",
    "        ax.scatter(x_t, y_t, color=\"#1E90FF\", edgecolor='k', zorder=3)\n",
    "        \n",
    "        # Axis labels & title\n",
    "        ax.set_xlabel(\"Relative Nodal concentration ($[N_c]$-$[N_p]$)\")\n",
    "        ax.set_ylabel(\"Central Lefty concentration ($L_c$)\")\n",
    "        ax.set_title(\"Patterning phase space\")\n",
    "        \n",
    "        # Colorbar for velocity\n",
    "        # cbar = fig.colorbar(strm.lines, ax=ax, label=\"Speed\")\n",
    "        \n",
    "        # ax.legend()\n",
    "    \n",
    "        # ax.set_xscale(\"log\")  # for x-axis\n",
    "        # ax.set_yscale(\"log\")  # for y-axis\n",
    "        # plt.show()\n",
    "        \n",
    "        fig.savefig(frame_folder / f\"phase_frame{t:04}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "121*3463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

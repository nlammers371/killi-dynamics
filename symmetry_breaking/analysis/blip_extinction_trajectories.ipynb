{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from compile_sweep_results import compile_sweep_results\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "root = Path(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/symmetry_breaking/sweep_results/\")\n",
    "sweep_name = \"sweep05_extinction\"\n",
    "output_dir = root / sweep_name\n",
    "fig_path = Path(\"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/slides/killifish/20250815/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for path in tqdm(output_dir.glob(\"*.json\")):\n",
    "    # First try pandas' JSON reader for Series format\n",
    "    s = pd.read_json(path, typ=\"series\")\n",
    "    s = s.copy()\n",
    "    s[\"__source_file__\"] = path.name\n",
    "    s[\"sim_id\"] = s[\"__source_file__\"].replace(\"result_\", \"\").replace(\".json\", \"\")\n",
    "    rows.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Compile results into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_cols = [\"Activator\", \"Repressor\", \"rho\"]\n",
    "skip_cols = [\"x\", \"times\"] + array_cols\n",
    "param_cols = [col for col in rows[0].keys() if col not in [\"sim_id\"] + skip_cols]\n",
    "param_cols = [\"sim_id\"] + param_cols\n",
    "\n",
    "x_grid = (np.asarray(rows[0][\"x\"]) - 1500)[:, None]\n",
    "t_grid = np.asarray(rows[0][\"times\"])[:, None]\n",
    "x_cols = [f\"x{i:04}\" for i in range(len(x_grid))]\n",
    "\n",
    "param_dfs = []\n",
    "activator_dfs = []\n",
    "repressor_dfs = []\n",
    "rho_dfs = []\n",
    "skipped = 0\n",
    "# iterate\n",
    "for row in tqdm(rows):\n",
    "\n",
    "    # params\n",
    "    p_temp = pd.DataFrame(row[param_cols])\n",
    "    param_dfs.append(p_temp.T)\n",
    "    try:\n",
    "        sim_id_vec = np.tile(row[\"sim_id\"], len(t_grid))[:, None]\n",
    "        # N df\n",
    "        a_array = np.asarray(row[\"Activator\"])\n",
    "        a_temp = pd.DataFrame(np.c_[sim_id_vec, t_grid, a_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "        activator_dfs.append(a_temp)\n",
    "        # L df\n",
    "        r_array = np.asarray(row[\"Repressor\"])\n",
    "        r_temp = pd.DataFrame(np.c_[sim_id_vec, t_grid, r_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "        repressor_dfs.append(r_temp)\n",
    "        # rho df\n",
    "        rho_array = np.asarray(row[\"rho\"])\n",
    "        rho_temp = pd.DataFrame(np.c_[sim_id_vec, t_grid, rho_array], columns=[\"sim_id\", \"t\"] + x_cols)\n",
    "        rho_dfs.append(rho_temp)\n",
    "    except:\n",
    "        skipped += 1\n",
    "\n",
    "\n",
    "Nodal_df = pd.concat(activator_dfs, axis=0, ignore_index=True)\n",
    "Lefty_df = pd.concat(repressor_dfs, axis=0, ignore_index=True)\n",
    "rho_df = pd.concat(rho_dfs, axis=0, ignore_index=True)\n",
    "param_df = pd.concat(param_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "Nodal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Calculate profile stats/trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_N = 10\n",
    "sigma_L = 10\n",
    "mu_L = 0.0002275846\n",
    "mu_N = mu_L * 1.11e-4/0.61e-4\n",
    "\n",
    "N_factor = sigma_N / mu_N\n",
    "L_factor = sigma_L / mu_L\n",
    "\n",
    "# target domain sigma: 250\n",
    "d_sigma = 250\n",
    "ref_grid = x_grid.ravel()\n",
    "# generate calculation masks\n",
    "mid_mask = np.abs(ref_grid) <= d_sigma\n",
    "left_mask = ref_grid < -d_sigma\n",
    "right_mask = ref_grid > d_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodal_factor_vec = np.tile(np.asarray(np.divide(sigma_N, param_df[\"mu_L\"]*,))[:, None], len(t_grid))\n",
    "# lefty_factor_vec = np.tile(np.asarray(np.divide(param_df[\"sigma_L\"], param_df[\"mu_L\"]))[:, None], len(t_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodal_array = Nodal_df.loc[:, x_cols].to_numpy().astype(float)\n",
    "N_left = np.mean(nodal_array[:, left_mask==1], axis=1)\n",
    "N_center = np.mean(nodal_array[:, mid_mask==1], axis=1)\n",
    "N_right = np.mean(nodal_array[:, right_mask==1], axis=1)\n",
    "\n",
    "lefty_array = Lefty_df.loc[:, x_cols].to_numpy().astype(float)\n",
    "L_left = np.mean(lefty_array[:, left_mask==1], axis=1)\n",
    "L_center = np.mean(lefty_array[:, mid_mask==1], axis=1)\n",
    "L_right = np.mean(lefty_array[:, right_mask==1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_df = pd.DataFrame(Nodal_df.loc[:, [\"sim_id\", \"t\"]]).merge(param_df, how=\"left\", on=\"sim_id\")\n",
    "pattern_df[\"t\"] = pattern_df[\"t\"].astype(float)\n",
    "pattern_df[\"N_left\"] = N_left #/ N_factor\n",
    "pattern_df[\"N_center\"] = N_center #/ N_factor\n",
    "pattern_df[\"N_right\"] = N_right #/ N_factor\n",
    "pattern_df[\"N_delta\"] = pattern_df[\"N_center\"] - pattern_df[\"N_left\"]\n",
    "pattern_df[\"N_delta_n\"] = pattern_df[\"N_delta\"].copy() / np.max(pattern_df[\"N_delta\"])\n",
    "\n",
    "pattern_df[\"L_left\"] = L_left #/ N_factor\n",
    "pattern_df[\"L_center\"] = L_center  #/ N_factor\n",
    "pattern_df[\"L_right\"] = L_right#/ N_factor\n",
    "pattern_df[\"L_delta\"] = pattern_df[\"L_center\"] - pattern_df[\"L_left\"]\n",
    "pattern_df[\"L_center_n\"] = pattern_df[\"L_center\"].copy() / np.max(pattern_df[\"L_center\"])\n",
    "\n",
    "pattern_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pattern_df, x=\"N_center\", y=\"N_left\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(pattern_df.loc[pattern_df[\"N_amp\"]<10], x=\"N_delta\", y=\"L_center\", color=\"t\", hover_data={\"sim_id\"})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic_2d\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "def compute_flux_grid(df, grid_size=250, log=False, interp_res=250, \n",
    "                      id_col = \"sim_id\",\n",
    "                      x_col = \"N_delta_n\",\n",
    "                      y_col = \"L_center_n\"):\n",
    "    \"\"\"\n",
    "    Compute a dense interpolated flux field for streamplot from simulation trajectories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must have columns: sim_id, t, N_delta, L_center\n",
    "    grid_size : int\n",
    "        Number of bins for coarse binning before interpolation.\n",
    "    log : bool\n",
    "        If True, bin in log10 space for both axes.\n",
    "    interp_res : int\n",
    "        Resolution of final interpolated grid for plotting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xi, Yi : 2D arrays\n",
    "        Meshgrid coordinates (uniform spacing).\n",
    "    Ui, Vi : 2D arrays\n",
    "        Interpolated vector field components.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # id_col = \"sim_id\"\n",
    "    # x_col = \"N_delta_n\"\n",
    "    # y_col = \"L_center_n\"\n",
    "\n",
    "    # Compute per-step deltas\n",
    "    df[\"dx\"] = df.groupby(id_col)[x_col].shift(-1) - df[x_col]\n",
    "    df[\"dy\"] = df.groupby(id_col)[y_col].shift(-1) - df[y_col]\n",
    "    df = df.dropna(subset=[\"dx\", \"dy\"])\n",
    "\n",
    "    # Choose coordinates\n",
    "    if log:\n",
    "        Xdata = np.log10(df[x_col].to_numpy())\n",
    "        Ydata = np.log10(df[y_col].to_numpy())\n",
    "    else:\n",
    "        Xdata = df[x_col].to_numpy()\n",
    "        Ydata = df[y_col].to_numpy()\n",
    "\n",
    "    Udata = df[\"dx\"].to_numpy()\n",
    "    Vdata = df[\"dy\"].to_numpy()\n",
    "\n",
    "    # Coarse bin edges\n",
    "    xbins = np.linspace(Xdata.min(), Xdata.max(), grid_size)\n",
    "    ybins = np.linspace(Ydata.min(), Ydata.max(), grid_size)\n",
    "\n",
    "    # Bin-averaged velocity components\n",
    "    U_avg, _, _, _ = binned_statistic_2d(Xdata, Ydata, Udata, statistic='mean', bins=[xbins, ybins])\n",
    "    V_avg, _, _, _ = binned_statistic_2d(Xdata, Ydata, Vdata, statistic='mean', bins=[xbins, ybins])\n",
    "\n",
    "    U_avg = U_avg.T\n",
    "    V_avg = V_avg.T\n",
    "    \n",
    "    # Bin centers\n",
    "    x_centers = 0.5 * (xbins[:-1] + xbins[1:])\n",
    "    y_centers = 0.5 * (ybins[:-1] + ybins[1:])\n",
    "    Xc, Yc = np.meshgrid(x_centers, y_centers, indexing=\"xy\")\n",
    "\n",
    "    # Prepare valid points for interpolation\n",
    "    mask = ~np.isnan(U_avg) & ~np.isnan(V_avg)\n",
    "    points = np.column_stack((Xc[mask], Yc[mask]))\n",
    "    Uvals = U_avg[mask]\n",
    "    Vvals = V_avg[mask]\n",
    "\n",
    "    # Dense uniform interpolation grid\n",
    "    Xi = np.linspace(Xdata.min(), Xdata.max(), interp_res)\n",
    "    Yi = np.linspace(Ydata.min(), Ydata.max(), interp_res)\n",
    "    Xi, Yi = np.meshgrid(Xi, Yi, indexing=\"xy\")\n",
    "\n",
    "    Ui = griddata(points, Uvals, (Xi, Yi), method='linear', fill_value=0)\n",
    "    Vi = griddata(points, Vvals, (Xi, Yi), method='linear', fill_value=0)\n",
    "\n",
    "    return Xi, Yi, Ui, Vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "X, Y, U, V = compute_flux_grid(pattern_df, grid_size=100, log=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plot_indices = np.random.choice(3125, n_plot)\n",
    "x_col = \"N_delta_n\"\n",
    "y_col = \"L_center_n\"\n",
    "\n",
    "_, t_rank = np.unique(pattern_df[\"t\"], return_inverse=True)\n",
    "pattern_df[\"t_int\"] = t_rank\n",
    "t_filter = pattern_df[\"t_int\"] < 10\n",
    "x_t = pattern_df.loc[t_filter, x_col].to_numpy()[plot_indices]\n",
    "y_t = pattern_df.loc[t_filter, y_col].to_numpy()[plot_indices]\n",
    "\n",
    "speed = np.sqrt(U**2 + V**2)\n",
    "\n",
    "# Make the plot\n",
    "with plt.style.context(\"dark_background\"):\n",
    "    \n",
    "    # cmap = mpl.cm.get_cmap('inferno')\n",
    "    # cmap_trunc = mpl.colors.ListedColormap(cmap(np.linspace(0, 0.8, 256)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    strm = ax.streamplot(\n",
    "        X, Y, U, V,\n",
    "        color=\"white\",\n",
    "        density=2\n",
    "    )\n",
    "    \n",
    "    # Scatter overlay\n",
    "    # ax.scatter(x_t, y_t, color='black', edgecolor='k', zorder=3, label='t points')\n",
    "    \n",
    "    # Axis labels & title\n",
    "    ax.set_xlabel(\"Relative Nodal concentration ($[N_c]$-$[N_p]$)\")\n",
    "    ax.set_ylabel(\"Central Lefty concentration ($L_c$)\")\n",
    "    ax.set_title(\"Patterning phase space\")\n",
    "    \n",
    "    # Colorbar for velocity\n",
    "    # cbar = fig.colorbar(strm.lines, ax=ax, label=\"Speed\")\n",
    "    # plt.style.use(\"dark_background\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(fig_path / \"survival_phase_diagram.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "np.random.seed(137)\n",
    "frame_folder = fig_path / \"phase_frames\"\n",
    "os.makedirs(frame_folder, exist_ok=True)\n",
    "\n",
    "n_plot = 1500\n",
    "ui, ni = np.unique(pattern_df[\"sim_id\"], return_counts=True)\n",
    "good_ids = ui[ni==121]\n",
    "\n",
    "x0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, x_col]\n",
    "y0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, y_col]\n",
    "s0 = pattern_df.loc[pattern_df[\"t_int\"] == 0, \"sim_id\"]\n",
    "high_ids = s0[(x0>=0.01) & (y0>=0.01)]\n",
    "\n",
    "# len(good_ids)\n",
    "# options = np.where(pattern_df[\"sim_id\"].isin(good_ids))[0]\n",
    "plot_ids = np.random.choice(good_ids, n_plot)\n",
    "id_filter = pattern_df[\"sim_id\"].isin(plot_ids) & pattern_df[\"sim_id\"].isin(high_ids)\n",
    "\n",
    "for t in tqdm(pattern_df[\"t_int\"].unique()):\n",
    "    \n",
    "    t_filter = (pattern_df[\"t_int\"] == t) & id_filter\n",
    "    x_t = pattern_df.loc[t_filter, x_col].to_numpy()\n",
    "    y_t = pattern_df.loc[t_filter, y_col].to_numpy()\n",
    "    \n",
    "    speed = np.sqrt(U**2 + V**2)\n",
    "    \n",
    "    # Make the plot\n",
    "    with plt.style.context(\"dark_background\"):\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        strm = ax.streamplot(\n",
    "            X, Y, U, V,\n",
    "            color=\"white\",\n",
    "            # cmap='viridis',\n",
    "            density=2\n",
    "        )\n",
    "        \n",
    "        # Scatter overlay\n",
    "        ax.scatter(x_t, y_t, color=\"#1E90FF\", edgecolor='k', zorder=3)\n",
    "        \n",
    "        # Axis labels & title\n",
    "        ax.set_xlabel(\"Relative Nodal concentration ($[N_c]$-$[N_p]$)\")\n",
    "        ax.set_ylabel(\"Central Lefty concentration ($L_c$)\")\n",
    "        ax.set_title(\"Patterning phase space\")\n",
    "        \n",
    "        # Colorbar for velocity\n",
    "        # cbar = fig.colorbar(strm.lines, ax=ax, label=\"Speed\")\n",
    "        \n",
    "        # ax.legend()\n",
    "    \n",
    "        # ax.set_xscale(\"log\")  # for x-axis\n",
    "        # ax.set_yscale(\"log\")  # for y-axis\n",
    "        # plt.show()\n",
    "        \n",
    "        fig.savefig(frame_folder / f\"phase_frame{t:04}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "121*3463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

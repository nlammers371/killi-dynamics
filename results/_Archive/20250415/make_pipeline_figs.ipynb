{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from src.utilities.plot_functions import format_2d_plotly, format_3d_plotly, rotate_figure\n",
    "from ultrack.tracks.graph import get_paths_to_roots, tracks_df_forest, inv_tracks_df_forest\n",
    "from glob2 import glob\n",
    "from tqdm import tqdm\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"E:\\\\Nick\\\\Cole Trapnell's Lab Dropbox\\\\Nick Lammers\\\\Nick\\\\killi_tracker\\\\\"\n",
    "\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "os.environ[\"PYQTGRAPH_QT_LIB\"] = \"PyQt5\"\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "\n",
    "project_name = \"20250311_LCP1-NLSMSC\"\n",
    "stitch_suffix = \"\"\n",
    "fig_path = os.path.join(root, \"figures\", project_name, \"pipeline_figs\", \"\")\n",
    "os.makedirs(fig_path, exist_ok=True)\n",
    "# load image dataset\n",
    "zpath = os.path.join(root, \"built_data\", \"zarr_image_files\", project_name + \"_fused.zarr\")\n",
    "fused_image_zarr = zarr.open(zpath, mode=\"r\")\n",
    "\n",
    "# load full tracking dataset\n",
    "print(\"Loading tracking data for project:\", project_name)\n",
    "nls_track_path = os.path.join(root, \"tracking\", project_name, \"tracking_20250328_redux\", \"well0000\", \"track_0000_2339_cb\", \"\")\n",
    "nls_tracks_df = pd.read_csv(os.path.join(nls_track_path, \"tracks\" + stitch_suffix + \"_fluo.csv\"))\n",
    "nucleus_class_df = pd.read_csv(os.path.join(nls_track_path, \"track_class_df_full.csv\"))\n",
    "\n",
    "# add class info to tracks\n",
    "nls_tracks_df = nls_tracks_df.merge(nucleus_class_df.loc[:, [\"track_id\", \"t\", \"track_class\", \"frame_class\"]], on=[\"track_id\", \"t\"], how=\"left\")\n",
    "nls_tracks_df.loc[:, \"z_scaled\"] = nls_tracks_df[\"z\"].copy() * 3\n",
    "\n",
    "print(\"Loading lcp tracking data for project:\", project_name)\n",
    "lcp_track_path = os.path.join(root, \"built_data\", \"tracking\", project_name, \"\")\n",
    "lcp_tracks_df = pd.read_csv(os.path.join(lcp_track_path, \"lcp_tracks_df.csv\"))\n",
    "\n",
    "lcp_curation_df = pd.read_csv(os.path.join(lcp_track_path, \"20250311_lcp_track_curation.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full mask dataset\n",
    "full_mask_fluo_dir = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_frames = sorted(glob(full_mask_fluo_dir + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for df_path in tqdm(fluo_frames):\n",
    "    df = pd.read_csv(df_path)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df_full = pd.concat(fluo_df_list, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figure directory\n",
    "fig_path = os.path.join(root, \"figures\", project_name)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "weights = fluo_df_full[\"mean_fluo\"].to_numpy()**6/np.sum(fluo_df_full[\"mean_fluo\"].to_numpy()**6)\n",
    "n_plot = 100000\n",
    "np.random.seed(134)\n",
    "plot_indices = np.random.choice(fluo_df_full.shape[0], n_plot, replace=False, p=weights)\n",
    "\n",
    "fluo_df_full[\"stage\"] = fluo_df_full[\"frame\"]*1.5/60 + 26\n",
    "\n",
    "fig = px.scatter(fluo_df_full.loc[plot_indices], x=\"stage\", y=\"mean_fluo\")\n",
    "axis_labels = [\"stage (hpf)\", \"nuclear lcp-gfp intensity (au)\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=5))\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"lcp_intensity_by_stage.png\"), scale=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot numbers of lcp+ cells over time according to our various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_thresh = 115\n",
    "window_size = 50\n",
    "\n",
    "fluo_df_full[\"fluo_flag\"] = (fluo_df_full[\"mean_fluo\"] > fluo_thresh).astype(float)\n",
    "master_df_g = fluo_df_full.loc[:, [\"stage\", \"fluo_flag\"]].groupby([\"stage\"]).sum().reset_index()\n",
    "\n",
    "master_df_g['fluo_trend'] = master_df_g['fluo_flag']\\\n",
    "    .transform(lambda s: s.rolling(window=window_size, min_periods=1).mean())\n",
    "\n",
    "fig = px.line(master_df_g, x=\"stage\", y=\"fluo_trend\")\n",
    "axis_labels = [\"stage (hpf)\", \"number of lcp+ cells\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=5))\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"lcp_cell_count_by_stage.png\"), scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## li threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_df = pd.read_csv(\"E:\\\\Nick\\\\Cole Trapnell's Lab Dropbox\\\\Nick Lammers\\\\Nick\\\\killi_tracker\\\\built_data\\\\mask_stacks\\\\20250311_LCP1-NLSMSCside1_li_thresh_trend.csv\")\n",
    "li_df[\"stage\"] = li_df[\"frame\"]*1.5/60 + 26\n",
    "\n",
    "fig = px.line(li_df, x=\"stage\", y=\"li_thresh\")\n",
    "axis_labels = [\"stage (hpf)\", \"inferred segmentation threshold\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=6, color=\"coral\"))\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"li_thresh_by_stage.png\"), scale=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of cells (total) and by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts_df = nls_tracks_df.groupby([\"t\"]).size().reset_index(name=\"number of cells\")\n",
    "window_size = 25\n",
    "total_counts_df[\"number of cells\"] = total_counts_df[\"number of cells\"].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "total_counts_df[\"stage\"] = total_counts_df[\"t\"]*1.5/60 + 26\n",
    "\n",
    "fig = px.line(total_counts_df, x=\"stage\", y=\"number of cells\")\n",
    "axis_labels = [\"stage (hpf)\", \"number of cells\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "fig.update_traces(line=dict(width=5, color=\"white\"))\n",
    "fig.write_image(os.path.join(fig_path, \"total_cell_count_by_stage.png\"), scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 0.  per‑frame raw counts\n",
    "cell_type_counts = (nls_tracks_df\n",
    "        .groupby([\"t\", \"track_class\"])\n",
    "        .size()\n",
    "        .rename(\"n_cells\")               # Series → name it\n",
    "        .reset_index())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1.  add missing (t, class) rows and fill with 0\n",
    "all_t       = np.arange(nls_tracks_df[\"t\"].min(),\n",
    "                        nls_tracks_df[\"t\"].max() + 1)\n",
    "all_classes = cell_type_counts[\"track_class\"].unique()\n",
    "\n",
    "full_index = pd.MultiIndex.from_product(\n",
    "                    [all_t, all_classes],\n",
    "                    names=[\"t\", \"track_class\"])\n",
    "\n",
    "cell_type_counts = (cell_type_counts\n",
    "        .set_index([\"t\", \"track_class\"])\n",
    "        .reindex(full_index, fill_value=0)      # missing → 0\n",
    "        .reset_index())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2.  centred rolling mean (window = 25)\n",
    "window_size = 50\n",
    "cell_type_counts = (cell_type_counts\n",
    "        .sort_values([\"track_class\", \"t\"])\n",
    "        .assign(**{\n",
    "            \"number of cells\": (\n",
    "                cell_type_counts\n",
    "                .sort_values([\"track_class\", \"t\"])         # ensure order\n",
    "                .groupby(\"track_class\")[\"n_cells\"]\n",
    "                .transform(lambda s:\n",
    "                           s.rolling(window_size,\n",
    "                                     center=True,\n",
    "                                     min_periods=1).mean())\n",
    "            )\n",
    "        }))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3.  stage (hpf)\n",
    "cell_type_counts[\"stage\"] = cell_type_counts[\"t\"] * 1.5 / 60 + 26\n",
    "\n",
    "name_map = {\n",
    "    0: \"deep\",\n",
    "    1: \"EVL\",\n",
    "    2: \"YSN\",\n",
    "}\n",
    "\n",
    "cell_type_counts = cell_type_counts.replace({\"track_class\": name_map})\n",
    "\n",
    "fig = px.line(cell_type_counts, x=\"stage\", y=\"number of cells\", color=\"track_class\", labels={\"track_class\":\"cell type\"},\n",
    "              color_discrete_map={\"deep\": \"blueviolet\"})\n",
    "axis_labels = [\"stage (hpf)\", \"number of cells\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "fig.update_traces(line=dict(width=5))\n",
    "fig.write_image(os.path.join(fig_path, \"cell_type_count_by_stage.png\"), scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask type segmentation figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1500\n",
    "\n",
    "# get image and seg\n",
    "seg_zarr = zarr.open(nls_track_path + \"segments.zarr\", mode=\"r\")\n",
    "seg_frame = seg_zarr[frame]\n",
    "im_frame = fused_image_zarr[frame, 1]\n",
    "\n",
    "# segment classes\n",
    "seg_df = nls_tracks_df.loc[nls_tracks_df[\"t\"]==frame, [\"track_id\", \"track_class\"]]\n",
    "deep_ids = seg_df.loc[seg_df[\"track_class\"]==0, \"track_id\"].to_numpy()\n",
    "evl_ids = seg_df.loc[seg_df[\"track_class\"]==1, \"track_id\"].to_numpy()\n",
    "ysn_ids = seg_df.loc[seg_df[\"track_class\"]==2, \"track_id\"].to_numpy()\n",
    "\n",
    "# get mask\n",
    "mask = np.zeros_like(seg_frame)\n",
    "mask[np.isin(seg_frame, deep_ids)] = 1\n",
    "mask[np.isin(seg_frame, evl_ids)] = 2\n",
    "mask[np.isin(seg_frame, ysn_ids)] = 3\n",
    "\n",
    "# max project\n",
    "im_max = np.max(im_frame, axis=0)\n",
    "seg_max = np.max(seg_frame, axis=0)\n",
    "mask_max = np.max(mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from napari.utils.colormaps import label_colormap\n",
    "from pathlib import Path\n",
    "\n",
    "def save_fig(img, path, *, dpi=600):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(fig_path / path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "clim = [30, 1200]\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  panel A – im_max only (grayscale)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(im_max, cmap=\"gray\", vmin=clim[0], vmax=clim[1])\n",
    "ax.axis(\"off\")\n",
    "fig.savefig(os.path.join(fig_path, \"im_max.png\"), dpi=600, bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()\n",
    "# ------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.  panel B – seg_max overlay (cyan, 40 % α)\n",
    "# ONE helper that returns a ListedColormap\n",
    "def discrete_cmap(n, *, seed=0):\n",
    "    \"\"\"Return a reproducible n‑colour colormap (label 0 = transparent).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    colors = rng.random((n + 1, 4))            # RGBA 0‑1\n",
    "    colors[0] = (0, 0, 0, 0)                   # label 0 fully transparent\n",
    "    return ListedColormap(colors)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "n_labels = int(seg_max.max())                  # highest integer in seg_max\n",
    "seg_cmap = discrete_cmap(n_labels, seed=42)    # 1 → random colour 1, …\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(im_max, cmap=\"gray\")                 # background\n",
    "ax.imshow(seg_max, cmap=seg_cmap, interpolation=\"nearest\")              # one line: overlay\n",
    "ax.axis(\"off\")\n",
    "fig.savefig(os.path.join(fig_path, \"im_seg_max_overlay.png\"), dpi=600, bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "#\n",
    "# # ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  panel C – mask_max overlay (1 → magenta, 2 → red, 3 → green)\n",
    "mask_cmap = ListedColormap([\n",
    "    (0, 0, 0, 0),        # 0 → fully transparent\n",
    "    (1, 0, 1, 0.5),      # 1 → magenta, 50 % α\n",
    "    (1, 0, 0, 0.5),      # 2 → red,     50 % α\n",
    "    (0, 1, 0, 0.5),      # 3 → green,   50 % α\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(im_max, cmap=\"gray\")\n",
    "ax.imshow(mask_max, cmap=mask_cmap, vmin=0, vmax=3)#, interpolate=\"nearest\")  # one line: overlay\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(fig_path, \"im_mask_max_overlay.png\"), dpi=600, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sphere fitting stuff...just density plot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spherical coordinates oriented relative to high dome position\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "sphere_df = pd.read_csv(os.path.join(nls_track_path, \"sphere_fit.csv\"))\n",
    "start_frame_max = 25\n",
    "phi_shift_manual = 60 / 180 * np.pi\n",
    "\n",
    "deep_tracks_df = nls_tracks_df.loc[nls_tracks_df[\"track_class\"]==0, [\"t\", \"x\", \"y\", \"z_scaled\"]].copy()\n",
    "\n",
    "start_filter = deep_tracks_df[\"t\"] <= start_frame_max\n",
    "start_indices = np.where(start_filter)[0]\n",
    "\n",
    "# 1) pull out your sphere center in (x,y,z) order\n",
    "sphere_center = sphere_df .loc[sphere_df[\"t\"]==0, [\"xs\",\"ys\",\"zs\"]] \\\n",
    "                          .iloc[0] \\\n",
    "                          .to_numpy()    # [x0,y0,z0]\n",
    "sphere_radius = sphere_df .loc[sphere_df[\"t\"]==0, [\"r\"]] \\\n",
    "                          .iloc[0] \\\n",
    "                          .to_numpy()\n",
    "\n",
    "# 2) center‐of‐mass also in (x,y,z)\n",
    "start_filter = deep_tracks_df[\"t\"] <= start_frame_max\n",
    "deep_cm = ( deep_tracks_df\n",
    "            .loc[start_filter, [\"x\",\"y\",\"z_scaled\"]]\n",
    "            .to_numpy()\n",
    "            .mean(axis=0) )                  # [x̄,ȳ,z̄]\n",
    "\n",
    "# 3) up‐vector = direction from sphere_center → deep_cm\n",
    "orientation_vec = deep_cm - sphere_center\n",
    "v = orientation_vec / np.linalg.norm(orientation_vec)\n",
    "\n",
    "rot, _ = R.align_vectors([[0,0,1]], [v])\n",
    "# Note: align_vectors(A,B) finds R so that R @ A[i] ≈ B[i],\n",
    "# so here we align the *z‑axis* to your v.\n",
    "# If you prefer the opposite convention, swap the lists.\n",
    "\n",
    "Rmat = rot.as_matrix()\n",
    "\n",
    "# 3) apply R to all points (shift first)\n",
    "pts = deep_tracks_df.loc[:, [\"x\",\"y\",\"z_scaled\"]].to_numpy() - sphere_center\n",
    "pts_rot = (Rmat @ pts.T).T   # now “pole” is z\n",
    "\n",
    "# 4) compute standard spherical coords\n",
    "x, y, z = pts_rot[:,0], pts_rot[:,1], pts_rot[:,2]\n",
    "r   = np.linalg.norm(pts_rot, axis=1)\n",
    "theta = np.arccos(np.clip(z/r, -1, 1))   # 0…π\n",
    "phi = np.arctan2(y, x)                 # –π…π\n",
    "phi += phi_shift_manual\n",
    "phi_wrapped = (phi + np.pi) % (2*np.pi) - np.pi\n",
    "deep_tracks_df[[\"r\",\"theta\",\"phi\"]] = np.column_stack([r, theta, phi_wrapped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "r, theta, phi = deep_tracks_df[\"r\"].to_numpy(), deep_tracks_df[\"theta\"].to_numpy(), deep_tracks_df[\"phi\"].to_numpy()\n",
    "# deep_tracks_df[[\"r\",\"theta\",\"phi\"]] = np.column_stack([r, theta, phi])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Example: N random points on (or near) the unit sphere\n",
    "t_vec = deep_tracks_df[\"t\"].to_numpy()\n",
    "\n",
    "lon = np.degrees(phi)                        # 0–360\n",
    "lat = 90 - np.degrees(theta)                       # 90 at pole … -90\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Robinson projection with Cartopy\n",
    "proj = ccrs.Robinson()\n",
    "xy = proj.transform_points(ccrs.PlateCarree(), lon, lat)\n",
    "x_proj, y_proj = xy[:,0], xy[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    # --------  backgrounds  --------\n",
    "    \"figure.facecolor\":  \"black\",\n",
    "    \"axes.facecolor\":    \"black\",\n",
    "    \"savefig.facecolor\": \"black\",\n",
    "    \"savefig.edgecolor\": \"black\",\n",
    "\n",
    "    # --------  text / lines  -------\n",
    "    \"text.color\":        \"white\",\n",
    "    \"axes.edgecolor\":    \"white\",\n",
    "    \"axes.labelcolor\":   \"white\",\n",
    "    \"xtick.color\":       \"white\",\n",
    "    \"ytick.color\":       \"white\",\n",
    "    \"grid.color\":        \"0.5\",\n",
    "\n",
    "    # brighter default colour‑cycle so traces stay visible\n",
    "    \"axes.prop_cycle\":   cycler(color=plt.cm.tab10.colors)\n",
    "})\n",
    "\n",
    "r, theta, phi = deep_tracks_df[\"r\"].to_numpy(), deep_tracks_df[\"theta\"].to_numpy(), deep_tracks_df[\"phi\"].to_numpy()\n",
    "# deep_tracks_df[[\"r\",\"theta\",\"phi\"]] = np.column_stack([r, theta, phi])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Example: N random points on (or near) the unit sphere\n",
    "t_vec = deep_tracks_df[\"t\"].to_numpy()\n",
    "\n",
    "lon = np.degrees(phi)                        # 0–360\n",
    "lat = 90 - np.degrees(theta)                       # 90 at pole … -90\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Robinson projection with Cartopy\n",
    "proj = ccrs.Robinson()\n",
    "xy = proj.transform_points(ccrs.PlateCarree(), lon, lat)\n",
    "x_proj, y_proj = xy[:,0], xy[:,1]\n",
    "\n",
    "\n",
    "\n",
    "# proj = ccrs.Robinson()\n",
    "nbins = 75\n",
    "t_window = 25\n",
    "hm_path = os.path.join(fig_path, \"density_hexbin\", \"\")\n",
    "os.makedirs(hm_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  CONSTANT MAP EXTENT (Robinson globe bounds)\n",
    "proj   = ccrs.Robinson()\n",
    "xlim   = proj.x_limits               # (-1.68e7 , +1.68e7)\n",
    "ylim   = proj.y_limits               # (-8.63e6 , +8.63e6)\n",
    "extent = (*xlim, *ylim)              # (xmin, xmax, ymin, ymax)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  BUILD OUTPUT FOLDER\n",
    "# hm_path = Path(fig_path) / \"density_hexbin\"\n",
    "# hm_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  SELECT FRAME WINDOW & NORMALISE\n",
    "for frame in tqdm(range(0, 2339, 25)):\n",
    "\n",
    "    t_filter   = (t_vec >= frame - t_window) & (t_vec <= frame + t_window)\n",
    "    n_frames   = len(np.unique(t_vec[t_filter]))   # number of frames in window\n",
    "    xp_frame   = x_proj[t_filter]\n",
    "    yp_frame   = y_proj[t_filter]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5.  INITIAL HEXBIN  (in axes coords, no projection needed here)\n",
    "    #     We need the bin centres to build the KD‑tree.\n",
    "    fig_tmp, ax_tmp = plt.subplots()\n",
    "    hb_tmp = ax_tmp.hexbin(\n",
    "            xp_frame, yp_frame,\n",
    "            gridsize=nbins,\n",
    "            extent=extent,\n",
    "            bins=None,                 # raw counts\n",
    "            mincnt=1,\n",
    "            cmap=\"hot_r\"\n",
    "    )\n",
    "    plt.close(fig_tmp)\n",
    "\n",
    "    counts  = hb_tmp.get_array()       # (M,)\n",
    "    centres = hb_tmp.get_offsets()     # (M, 2)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6.  SMOOTH COUNTS WITH K‑NEAREST AVERAGE\n",
    "    tree             = cKDTree(centres)\n",
    "    _, idxs           = tree.query(centres, k=6)       # includes self\n",
    "    counts_smooth     = counts[idxs].mean(axis=1) / n_frames\n",
    "    counts_raw        = counts / n_frames\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 7.  PLOT ON GLOBE\n",
    "    stage = frame * 1.5 / 60 + 26                     # hpf\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5),\n",
    "                           subplot_kw=dict(projection=proj))\n",
    "\n",
    "    hb = ax.hexbin(\n",
    "            centres[:, 0], centres[:, 1],\n",
    "            C=counts_smooth,\n",
    "            gridsize=nbins,\n",
    "            extent=extent,\n",
    "            reduce_C_function=np.mean,\n",
    "            cmap=\"inferno\",\n",
    "            vmin=0, vmax=1.5,\n",
    "            alpha=0.8,\n",
    "            linewidths=0,       # no edge lines\n",
    "        edgecolors='none'\n",
    "    )\n",
    "\n",
    "    ax.set_global()                 # same as set_xlim/ylim(xlim, ylim)\n",
    "\n",
    "    # cosmetics\n",
    "    fig.colorbar(hb, ax=ax, label=\"cell count\")\n",
    "    ax.set_title(f\"Deep cell density on embryonic surface ({stage:.2f} hpf)\")\n",
    "    ax.gridlines(draw_labels=True,\n",
    "                 xformatter=LongitudeFormatter(),\n",
    "                 yformatter=LatitudeFormatter())\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(\n",
    "        os.path.join(hm_path, f\"deep_cell_density_f{frame:04}.png\"),\n",
    "        dpi=600, bbox_inches=\"tight\"\n",
    "    )\n",
    "    # plt.show()\n",
    "\n",
    "    fig.savefig(os.path.join(hm_path, f\"deep_cell_density_f{frame:04}.png\"),\n",
    "                 dpi=600, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tracking qc figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultrack.tracks.graph import inv_tracks_df_forest\n",
    "from ultrack.tracks.gap_closing import tracks_starts, tracks_ends\n",
    "from tqdm import tqdm\n",
    "\n",
    "# calculate root node for each track\n",
    "child_to_parent_dict = inv_tracks_df_forest(nls_tracks_df)\n",
    "\n",
    "nls_tracks_df = pd.read_csv(os.path.join(nls_track_path, \"tracks\" + stitch_suffix + \"_fluo.csv\"))\n",
    "# initialize\n",
    "# deep_tracks_df[\"root_id\"] = -1\n",
    "# iterate over all tracks\n",
    "track_index = nls_tracks_df[\"track_id\"].unique()\n",
    "track_parent_dict = nls_tracks_df.loc[:, [\"track_id\", \"parent_track_id\"]].drop_duplicates().set_index('track_id')['parent_track_id'].to_dict()\n",
    "child_keys = np.asarray(child_to_parent_dict.keys())\n",
    "track_root_dict = track_parent_dict .copy()\n",
    "\n",
    "map_ids = []\n",
    "for track_id in tqdm(track_index):\n",
    "    parent_id = track_parent_dict[track_id]\n",
    "    if parent_id != -1:\n",
    "        map_ids.append(track_id)\n",
    "        # find root\n",
    "        while parent_id != -1:\n",
    "            curr_id = parent_id\n",
    "            if curr_id not in child_keys: # this signals we are at the root\n",
    "                break\n",
    "            parent_id = track_parent_dict[curr_id]\n",
    "        track_root_dict[track_id] = curr_id\n",
    "    else:\n",
    "        track_root_dict[track_id] = track_id\n",
    "\n",
    "# track_parent_dict[10]\n",
    "df = pd.DataFrame.from_dict(\n",
    "    track_root_dict,\n",
    "    orient='index',\n",
    "    columns=['root_id']\n",
    ")\n",
    "df.index.name = 'track_id'\n",
    "df = df.reset_index()\n",
    "\n",
    "nls_tracks_df = nls_tracks_df.merge(df, on=\"track_id\", how=\"left\")\n",
    "nls_tracks_df = nls_tracks_df.loc[nls_tracks_df[\"root_id\"] > 0, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts = nls_tracks_df.loc[:, [\"root_id\"]].groupby([\"root_id\"]).size().reset_index(name=\"n_time_points\")\n",
    "nls_tracks_df = nls_tracks_df.merge(track_counts, on=\"root_id\", how=\"left\")\n",
    "track_length = nls_tracks_df.loc[:, [\"t\", \"n_time_points\"]].groupby([\"t\"])[\"n_time_points\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_length[\"stage\"] = track_length[\"t\"] * 1.5 / 60 + 26\n",
    "track_length[\"track length\"] = track_length[\"n_time_points\"] * 1.5 / 60\n",
    "fig = px.line(track_length, x=\"stage\", y=\"track length\")\n",
    "axis_labels = [\"stage (hpf)\", \"average track length (hours)\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "fig.update_traces(line=dict(width=5, color=\"white\"))\n",
    "fig.write_image(os.path.join(fig_path, \"average_track_length_by_stage.png\"), scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) for each track, find its first frame and its total span\n",
    "track_stats = (\n",
    "    nls_tracks_df\n",
    "    .groupby(\"root_id\")[\"t\"]\n",
    "    .agg(start_frame=\"min\", end_frame=\"max\", n_time_points=\"nunique\")\n",
    "    .reset_index()\n",
    ")\n",
    "track_stats = track_stats.loc[track_stats[\"n_time_points\"]>1, :].copy()\n",
    "#    columns = ['root_id','start_frame','end_frame','n_time_points']\n",
    "\n",
    "# 2) now average the lifespans by their start_frame\n",
    "avg_by_start = (\n",
    "    track_stats\n",
    "    .groupby(\"start_frame\")[\"n_time_points\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"avg_length\")\n",
    ")\n",
    "\n",
    "# 3) if you want to convert start_frame → hours post‑fertilisation:\n",
    "avg_by_start[\"start_hpf\"] = avg_by_start[\"start_frame\"] * 1.5/60 + 26\n",
    "avg_by_start[\"avg_length\"] = avg_by_start[\"avg_length\"].rolling(window=35, center=True, min_periods=1).mean()\n",
    "avg_by_start[\"avg_length_hr\"] = avg_by_start[\"avg_length\"] * 1.5/60\n",
    "\n",
    "# 4) plot it\n",
    "import plotly.express as px\n",
    "fig = px.line(\n",
    "    avg_by_start,\n",
    "    x=\"start_hpf\",\n",
    "    y=\"avg_length_hr\",\n",
    "    labels={\"start_hpf\":\"track start (hpf)\", \"avg_length\":\"mean track length (hours)\"},\n",
    ")\n",
    "\n",
    "fig = format_2d_plotly(fig, font_size=18, axis_labels=[\"track start (hpf)\", \"mean track length (hours)\"])\n",
    "\n",
    "fig.update_traces(line=dict(width=5, color=\"white\"))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"avg_track_length_by_start.png\"), scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# ── 1) per‐track stats ─────────────────────────────────────────────────────\n",
    "track_stats = (\n",
    "    nls_tracks_df\n",
    "    .groupby(\"root_id\")[\"t\"]\n",
    "    .agg(\n",
    "        start_frame   = \"min\",\n",
    "        n_time_points = \"nunique\"   # total duration in frames\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "# drop single‐frame tracks if desired\n",
    "track_stats = track_stats[track_stats[\"n_time_points\"] > 1].copy()\n",
    "\n",
    "# ── 2) summary by start_frame ────────────────────────────────────────────\n",
    "def p10(x): return x.quantile(0.10)\n",
    "def p90(x): return x.quantile(0.90)\n",
    "\n",
    "summary = (\n",
    "    track_stats\n",
    "    .groupby(\"start_frame\")[\"n_time_points\"]\n",
    "    .agg(\n",
    "        mean_length = \"mean\",\n",
    "        p10_length  = p10,\n",
    "        p90_length  = p90,\n",
    "        count       = \"size\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ── 3) convert to hpf / hours ─────────────────────────────────────────────\n",
    "summary[\"start_hpf\"]   = summary[\"start_frame\"] * 1.5/60 + 26\n",
    "summary[\"mean_hr\"]     = summary[\"mean_length\"] * 1.5/60\n",
    "summary[\"p10_hr\"]      = summary[\"p10_length\"]  * 1.5/60\n",
    "summary[\"p90_hr\"]      = summary[\"p90_length\"]  * 1.5/60\n",
    "\n",
    "# optional smoothing over starts\n",
    "for col in [\"mean_hr\", \"p10_hr\", \"p90_hr\"]:\n",
    "    summary[col] = (\n",
    "        summary[col]\n",
    "        .rolling(window=35, center=True, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "# ── 4) plotly: mean + 10th/90th percentile ───────────────────────────────\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=summary[\"start_hpf\"],\n",
    "        y=summary[\"mean_hr\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Mean\",\n",
    "        line=dict(color=\"white\", width=4)\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=summary[\"start_hpf\"],\n",
    "        y=summary[\"p10_hr\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"10th percentile\",\n",
    "        line=dict(color=\"lightblue\", width=2, dash=\"dash\")\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=summary[\"start_hpf\"],\n",
    "        y=summary[\"p90_hr\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"90th percentile\",\n",
    "        line=dict(color=\"orange\", width=2, dash=\"dash\")\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=pd.concat([summary[\"start_hpf\"], summary[\"start_hpf\"][::-1]]),\n",
    "        y=pd.concat([summary[\"p90_hr\"], summary[\"p10_hr\"][::-1]]),\n",
    "        fill=\"toself\",\n",
    "        fillcolor=\"rgba(255,165,0,0.2)\",\n",
    "        line=dict(width=0),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=True,\n",
    "        name=\"10–90 percentile band\"\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_dark\",\n",
    "    xaxis_title=\"Track start (hpf)\",\n",
    "    yaxis_title=\"Track duration (hours)\",\n",
    "    font=dict(size=16, color=\"white\"),\n",
    "    legend=dict(bgcolor=\"rgba(0,0,0,0.5)\")\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\n",
    "    os.path.join(fig_path, \"track_length_summary_by_start.png\"),\n",
    "    scale=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

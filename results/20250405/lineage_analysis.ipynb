{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from ultrack.tracks.graph import get_paths_to_roots, tracks_df_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T01:48:27.588714400Z",
     "start_time": "2025-04-13T01:48:26.753020800Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/killi_tracker/tracking\\\\20250311_LCP1-NLSMSC_local\\\\tracking_20250328_redux\\\\well0000\\\\track_0000_2339_cb\\\\tracks_fluo.csv\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m tracking_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrack_0000_2339_cb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      7\u001B[0m track_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtracking\u001B[39m\u001B[38;5;124m\"\u001B[39m, project_name, tracking_config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwell0000\u001B[39m\u001B[38;5;124m\"\u001B[39m, tracking_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtracks_fluo.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m tracks_df_raw \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrack_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m track_path_s \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtracking\u001B[39m\u001B[38;5;124m\"\u001B[39m, project_name, tracking_config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwell0000\u001B[39m\u001B[38;5;124m\"\u001B[39m, tracking_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtracks_fluo_stitched.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m tracks_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(track_path_s)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\kf-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\kf-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\kf-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\kf-processing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\kf-processing\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/killi_tracker/tracking\\\\20250311_LCP1-NLSMSC_local\\\\tracking_20250328_redux\\\\well0000\\\\track_0000_2339_cb\\\\tracks_fluo.csv\""
     ]
    }
   ],
   "source": [
    "# load tracks dataset\n",
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/killi_tracker/\"\n",
    "project_name = \"20250311_LCP1-NLSMSC_local\"\n",
    "tracking_config = \"tracking_20250328_redux\"\n",
    "tracking_name = \"track_0000_2339_cb\"\n",
    "\n",
    "track_path = os.path.join(root, \"tracking\", project_name, tracking_config, \"well0000\", tracking_name, \"tracks_fluo.csv\")\n",
    "tracks_df_raw = pd.read_csv(track_path)\n",
    "track_path_s = os.path.join(root, \"tracking\", project_name, tracking_config, \"well0000\", tracking_name, \"tracks_fluo_stitched.csv\")\n",
    "tracks_df = pd.read_csv(track_path_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = os.path.join(root, \"figures\", \"tracking\", project_name, tracking_config)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw nucleus mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "fluo_path = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_df_path_list = sorted(glob(fluo_path + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for fluo_p in tqdm(fluo_df_path_list):\n",
    "    df = pd.read_csv(fluo_p)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df = pd.concat(fluo_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot numbers of cells over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from src.utilities.plot_functions import format_2d_plotly\n",
    "\n",
    "# get tracking-based counts\n",
    "tid, tc = np.unique(tracks_df[\"t\"], return_counts=True)\n",
    "counts_df = pd.DataFrame(tid, columns=[\"frame\"])\n",
    "counts_df[\"n_nuclei_track\"] = tc\n",
    "\n",
    "# get segmentation-based counts\n",
    "tidf, tcf = np.unique(fluo_df[\"frame\"], return_counts=True)\n",
    "counts_df[\"n_nuclei_seg\"] = tcf\n",
    "\n",
    "counts_df[\"stage\"] = 26 + counts_df[\"frame\"] * 1.5 / 60\n",
    "\n",
    "fig = px.line(counts_df, x=\"stage\", y=\"n_nuclei_seg\")\n",
    "\n",
    "axis_labels = [\"stage (hpf)\", \"number of nuclei\"]\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=4))\n",
    "\n",
    "fig.write_image(fig_path + \"n_cells_seg.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.line(counts_df, x=\"frame\", y=\"n_nuclei_seg\")\n",
    "\n",
    "fig.add_traces(go.Scatter(x=counts_df[\"frame\"], y=counts_df[\"n_nuclei_track\"], mode=\"lines\"))\n",
    "axis_labels = [\"stage (hpf)\", \"number of nuclei\"]\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=4))\n",
    "\n",
    "# fig.write_image(fig_path + \"n_cells_seg.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at emergence of lcp+ cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_thresh = 115\n",
    "\n",
    "# # initialize\n",
    "# full_frame_vec = np.arange(0, np.max(tracks_df[\"t\"])+1)\n",
    "# track_counts = np.zeros_like(full_frame_vec)\n",
    "# seg_counts = np.zeros_like(full_frame_vec)\n",
    "\n",
    "# # tracking data\n",
    "# track_df_ft = tracks_df[\"mean_fluo\"] > fluo_thresh\n",
    "# tr_frames, tr_counts_ = np.unique(tracks_df.loc[track_df_ft, \"t\"], return_counts=True)\n",
    "# track_counts[tr_frames.astype(int)] = tr_counts\n",
    "\n",
    "# # mask data\n",
    "# mask_df_ft = fluo_df[\"mean_fluo\"] > fluo_thresh\n",
    "# m_frames, m_counts = np.unique(fluo_df.loc[mask_df_ft, \"frame\"], return_counts=True)\n",
    "# seg_counts[m_frames.astype(int)] = m_counts\n",
    "\n",
    "# # generate data frame\n",
    "# lcp_df0 = pd.DataFrame(full_frame_vec, columns=[\"frame\"])\n",
    "# lcp_df0[\"n_lcp_cells\"] = track_counts\n",
    "# lcp_df0[\"data type\"] = \"tracking\"\n",
    "\n",
    "# lcp_df1 = pd.DataFrame(full_frame_vec, columns=[\"frame\"])\n",
    "# lcp_df1[\"n_lcp_cells\"] = seg_counts\n",
    "# lcp_df1[\"data type\"] = \"segmentation\"\n",
    "\n",
    "# lcp_df = pd.concat([lcp_df0, lcp_df1], ignore_index=True)\n",
    "# lcp_df[\"stage\"] = 26 + lcp_df[\"frame\"] * 1.5 / 60 \n",
    "\n",
    "# fig = px.scatter(lcp_df, x=\"stage\", y=\"n_lcp_cells\", color=\"data type\", trendline=\"ols\", opacity=0.5, trendline_options={\"poly_order\": 3})\n",
    "\n",
    "# # fig.update_traces()\n",
    "\n",
    "# axis_labels = [\"stage (hpf)\", \"number of detected lcp+ cells\"]\n",
    "# fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose a rolling window size (adjust based on your data):\n",
    "window_size = 40\n",
    "\n",
    "# Sort the DataFrame by stage so that rolling is done in the correct order:\n",
    "lcp_df = lcp_df.sort_values(\"stage\")\n",
    "\n",
    "# Group by \"data type\" and compute rolling mean and std.\n",
    "# Using min_periods=1 so that we still get values at the beginning.\n",
    "df_trend = lcp_df.groupby(\"data type\").apply(\n",
    "    lambda x: x.assign(\n",
    "        moving_avg=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).mean(),\n",
    "        moving_std=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).std()\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Use a defined color sequence from Plotly and build a mapping (you could also use a custom dictionary).\n",
    "color_sequence = px.colors.qualitative.Plotly\n",
    "unique_types = sorted(lcp_df[\"data type\"].unique())  # sort for consistency\n",
    "color_map = {dt: color for dt, color in zip(unique_types, color_sequence)}\n",
    "# Alternatively, you can pass a discrete map directly when calling px.scatter:\n",
    "fig = go.Figure()\n",
    "# px.scatter(\n",
    "#     lcp_df, \n",
    "#     x=\"stage\", \n",
    "#     y=\"n_lcp_cells\", \n",
    "#     color=\"data type\", \n",
    "#     color_discrete_map=color_map,\n",
    "#     opacity=0.5\n",
    "# )\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "# Calculate moving average and std (using a rolling window)\n",
    "lcp_df_sorted = lcp_df.sort_values(\"stage\")\n",
    "df_trend = lcp_df_sorted.groupby(\"data type\").apply(\n",
    "    lambda x: x.assign(\n",
    "        moving_avg=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).mean(),\n",
    "        moving_std=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).std()\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Utility: Convert HEX color to RGBA (for the translucent fill)\n",
    "def hex_to_rgba(hex_color, alpha=0.2):\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return f\"rgba({r},{g},{b},{alpha})\"\n",
    "\n",
    "# Add traces for each data type: trendline and shaded error band.\n",
    "for dt in unique_types:\n",
    "    df_sub = df_trend[df_trend[\"data type\"] == dt].copy()\n",
    "    # Get the color for this group from our mapping:\n",
    "    base_color = color_map[dt]\n",
    "    \n",
    "    # Add trendline (moving average) trace:\n",
    "    avg_trace = go.Scatter(\n",
    "        x=df_sub[\"stage\"],\n",
    "        y=df_sub[\"moving_avg\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"{dt}\",\n",
    "        line=dict(color=base_color, width=3)\n",
    "    )\n",
    "    fig.add_trace(avg_trace)\n",
    "\n",
    "    # Calculate upper and lower bounds:\n",
    "    upper_bound = df_sub[\"moving_avg\"] + df_sub[\"moving_std\"]\n",
    "    lower_bound = df_sub[\"moving_avg\"] - df_sub[\"moving_std\"]\n",
    "\n",
    "    # Create a translucent shaded region for ±1 standard deviation:\n",
    "    error_band_trace = go.Scatter(\n",
    "        x=np.concatenate([df_sub[\"stage\"].to_numpy(), df_sub[\"stage\"].to_numpy()[::-1]]),\n",
    "        y=np.concatenate([upper_bound.to_numpy(), lower_bound.to_numpy()[::-1]]),\n",
    "        fill=\"toself\",\n",
    "        fillcolor=hex_to_rgba(base_color, alpha=0.4),\n",
    "        line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "        name=f\"{dt} ±1 SD\"\n",
    "    )\n",
    "    fig.add_trace(error_band_trace)\n",
    "\n",
    "# Format the axes if desired (using your custom formatting function, for example):\n",
    "axis_labels = [\"stage (hpf)\", \"number of detected lcp+ cells\"]\n",
    "# Assuming format_2d_plotly is your custom function:\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(fig_path + \"n_lcp_cells_vs_stage.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments look shite. What about the raw masks?\n",
    "Manual inspection indicates that a number of raw masks corresponding to lcp+ nuclei are beingd dropped durring tracking, which is frustrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "fluo_path = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_df_path_list = sorted(glob(fluo_path + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for fluo_p in tqdm(fluo_df_path_list):\n",
    "    df = pd.read_csv(fluo_p)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df = pd.concat(fluo_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(fluo_df[\"mean_fluo\"]>fluo_thresh))\n",
    "print(np.sum(tracks_df[\"mean_fluo\"]>fluo_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see substantially more high-fluo frames. Let's look at trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50  # for example\n",
    "\n",
    "# Group by time 't' and, for each group, pick the N rows with the highest 'mean_fluo'\n",
    "top_fluo_df = fluo_df.groupby('frame', group_keys=False).apply(lambda x: x.nlargest(N, columns='mean_fluo')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(top_fluo_df, x=\"frame\", y=\"mean_fluo\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi, fc = np.unique(fluo_df.loc[fluo_df[\"mean_fluo\"]>fluo_thresh, \"frame\"], return_counts=True)\n",
    "\n",
    "fig = px.scatter(x=fi, y=fc)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we're losing a ton during the tracking process. Sad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess overall quality of the tracks. Can we reconstruct lineage trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultrack.tracks.graph import inv_tracks_df_forest\n",
    "\n",
    "forest_graph = tracks_df_forest(tracks_df)\n",
    "inv_forest_graph = inv_tracks_df_forest(tracks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root(cell, parent_map):\n",
    "    \"\"\"\n",
    "    Recursively follow the parent mapping until a cell is reached that has no parent.\n",
    "    Assumes parent_map[cell] returns a list of parent IDs (with one parent per cell).\n",
    "    \"\"\"\n",
    "    while cell in parent_map:\n",
    "        # For a simple 1-to-1 mapping, take the first (and only) parent.\n",
    "        cell = parent_map[cell]\n",
    "    return cell\n",
    "\n",
    "# Build a list of results for each child that is a key in parent_map.\n",
    "results = []\n",
    "track_index = np.unique(tracks_df[\"track_id\"])\n",
    "mapped_ids = np.asarray(list(inv_forest_graph.keys()))\n",
    "for child in tqdm(track_index):\n",
    "    if child in mapped_ids:\n",
    "        root = get_root(child, inv_forest_graph)\n",
    "    else:\n",
    "        root = child\n",
    "    # Look up the frame number for the root cell\n",
    "    root_frame = np.min(tracks_df.loc[tracks_df[\"track_id\"]==root, \"t\"])\n",
    "    leaf_frame = np.max(tracks_df.loc[tracks_df[\"track_id\"]==child, \"t\"])\n",
    "    results.append({'child_id': child, 'root_id': root, 'root_frame': root_frame, 'leaf_frame': leaf_frame})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_roots = pd.DataFrame(results)\n",
    "df_roots = df_roots.merge(counts_df, how=\"left\", left_on=\"child_id\", right_on=\"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roots_ft = df_roots.loc[df_roots[\"track_length\"] >= 10]\n",
    "print(df_roots_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roots_ft[\"span\"] = df_roots_ft[\"leaf_frame\"] - df_roots_ft[\"root_frame\"]\n",
    "\n",
    "fig = px.scatter(df_roots_ft, x=\"leaf_frame\", y=\"span\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultrack.tracks.gap_closing import close_tracks_gaps\n",
    "\n",
    "test = close_tracks_gaps(tracks_df, max_gap=3, max_radius=50, scale=np.asarray([3.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(test[\"track_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(tracks_df[\"track_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from src.utilities.plot_functions import format_2d_plotly\n",
    "from ultrack.tracks.graph import get_paths_to_roots, tracks_df_forest\n",
    "from glob2 import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/nick/Cole Trapnell's Lab Dropbox/Nick Lammers/Nick/killi_tracker/\"\n",
    "\n",
    "# main tracking dataset(s)\n",
    "project_name = \"20250311_LCP1-NLSMSC_local\"\n",
    "tracking_config = \"tracking_20250328_redux\"\n",
    "tracking_name0 = \"track_0000_2200\"\n",
    "tracking_name1 = \"track_2000_2339\"\n",
    "\n",
    "track_path0 = os.path.join(root, \"tracking\", project_name, tracking_config, \"well0000\", tracking_name0, \"tracks_stitched_fluo.csv\")\n",
    "tracks_df0 = pd.read_csv(track_path0)\n",
    "\n",
    "track_path1 = os.path.join(root, \"tracking\", project_name, tracking_config, \"well0000\", tracking_name1, \"tracks_stitched_fluo.csv\")\n",
    "tracks_df1 = pd.read_csv(track_path1)\n",
    "tracks_df1.loc[:, \"t\"] = tracks_df1.loc[:, \"t\"] + 2000\n",
    "# fluo mask-based tracking\n",
    "# main tracking dataset(s)\n",
    "project_name_m = \"20250311_LCP1-NLSMSC_marker_local\"\n",
    "tracking_config = \"tracking_20250328_redux\"\n",
    "tracking_name_m = \"track_1200_2339\"\n",
    "\n",
    "track_path_m = os.path.join(root, \"tracking\", project_name_m, tracking_config, \"well0000\", tracking_name_m, \"tracks_stitched_fluo.csv\")\n",
    "marker_tracks_df = pd.read_csv(track_path_m)\n",
    "marker_tracks_df.loc[:, \"t\"] = marker_tracks_df.loc[:, \"t\"] + 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full mask dataset\n",
    "full_mask_fluo_dir = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_frames = sorted(glob(full_mask_fluo_dir + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for df_path in tqdm(fluo_frames):\n",
    "    df = pd.read_csv(df_path)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df_full = pd.concat(fluo_df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# marker mask dataset\n",
    "marker_mask_fluo_dir = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name_m, \"\")\n",
    "marker_fluo_frames = sorted(glob(marker_mask_fluo_dir + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for df_path in tqdm(marker_fluo_frames):\n",
    "    df = pd.read_csv(df_path)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df_marker = pd.concat(fluo_df_list, axis=0, ignore_index=True)\n",
    "# fluo_df_marker.loc[:, \"frame\"] = fluo_df_marker.loc[:, \"frame\"] + 1200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(tracks_df0[\"t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df0[\"df\"] = \"main0\"\n",
    "tracks_df0 = tracks_df0.rename(columns={\"t\":\"frame\", \"track_id\":\"nucleus_id\", \"fluo_mean\":\"mean_fluo\"})\n",
    "tracks_df1[\"df\"] = \"main1\"\n",
    "tracks_df1 = tracks_df1.rename(columns={\"t\":\"frame\", \"track_id\":\"nucleus_id\", \"fluo_mean\":\"mean_fluo\"})\n",
    "marker_tracks_df[\"df\"] = \"marker\"\n",
    "marker_tracks_df = marker_tracks_df.rename(columns={\"t\":\"frame\", \"track_id\":\"nucleus_id\", \"fluo_mean\":\"mean_fluo\"})\n",
    "\n",
    "fluo_df_full[\"df\"] = \"mask\"\n",
    "fluo_df_marker[\"df\"] = \"mask_marker\"\n",
    "\n",
    "master_df = pd.concat([tracks_df0, tracks_df1, marker_tracks_df, fluo_df_full, fluo_df_marker], axis=0, ignore_index=True)\n",
    "master_df[\"stage\"] = 26 + master_df[\"frame\"]*1.5/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figure directory\n",
    "fig_path = os.path.join(root, \"figures\", \"tracking\", project_name, tracking_config)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot numbers of lcp+ cells over time according to our various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fluo_thresh = 115\n",
    "window_size = 25\n",
    "\n",
    "master_df[\"fluo_flag\"] = (master_df[\"mean_fluo\"] > fluo_thresh).astype(float)\n",
    "master_df_g = master_df.loc[:, [\"stage\", \"df\", \"fluo_flag\"]].groupby([\"stage\", \"df\"]).sum().reset_index()\n",
    "\n",
    "master_df_g['fluo_trend'] = master_df_g.groupby(['df'])['fluo_flag']\\\n",
    "    .transform(lambda s: s.rolling(window=window_size, min_periods=1).mean())\n",
    "\n",
    "fig = px.line(master_df_g, x=\"stage\", y=\"fluo_trend\", color=\"df\")\n",
    "axis_labels = [\"stage (hpf)\", \"number of lcp+ cells\"]\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "fig.update_traces(line=dict(width=5))\n",
    "\n",
    "fig.write_image(os.path.join(fig_path, \"lcp_cell_count_by_method.png\"), scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(76 - 26) * 60 / 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate apparent quality of lineage graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultrack.tracks.graph import tracks_df_forest, inv_tracks_df_forest\n",
    "from ultrack.tracks.gap_closing import tracks_starts, tracks_ends\n",
    "\n",
    "track_path0 = os.path.join(root, \"tracking\", project_name, tracking_config, \"well0000\", tracking_name0, \"tracks_stitched_fluo.csv\")\n",
    "tracks_df_test = pd.read_csv(track_path0)\n",
    "\n",
    "# get dict giving parent for each node\n",
    "leaf_to_root = inv_tracks_df_forest(tracks_df_test)\n",
    "\n",
    "# get start and end frames for each track id\n",
    "starts = tracks_starts(tracks_df_test)\n",
    "ends = tracks_ends(tracks_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how far back, on average, can we go?\n",
    "lineage_df = ends.copy().drop(labels=[\"parent_track_id\", \"id\"], axis=1).reset_index(drop=True)\n",
    "\n",
    "root_df_list = []\n",
    "child_id_key = np.asarray(list(leaf_to_root.keys()))\n",
    "for track_id in tqdm(lineage_df[\"track_id\"], \"tracing from leaf to root...\"):\n",
    "    \n",
    "    track_curr = track_id\n",
    "    n_layers = 0\n",
    "    while np.isin(track_curr, child_id_key):\n",
    "        track_curr = leaf_to_root[track_curr]\n",
    "        n_layers += 1\n",
    "\n",
    "    start_row = starts.loc[starts[\"track_id\"]==track_curr, [\"track_id\", \"t\", \"z\", \"y\", \"z\", \"fluo_mean\"]]\n",
    "    start_row[\"n_branches\"] = n_layers\n",
    "    start_row[\"leaf_id\"] = track_id\n",
    "    root_df_list.append(pd.DataFrame(start_row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating root df...\")\n",
    "root_df = pd.concat(root_df_list, axis=0, ignore_index=True)\n",
    "root_df = root_df.rename(columns={\"track_id\":\"root_id\", \"t\":\"ts\", \"z\":\"zs\", \"y\":\"ys\", \"x\":\"xs\", \"fluo_mean\":\"fluo_s\"})\n",
    "print(\"Merging...\")\n",
    "lineage_df = lineage_df.merge(root_df, how=\"left\", left_on=\"track_id\", right_on=\"leaf_id\")\n",
    "lineage_df[\"tree_length\"] = lineage_df[\"t\"] - lineage_df[\"ts\"]\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(lineage_df, x=\"tree_length\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(lineage_df, x=\"n_branches\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(lineage_df, x=\"t\", y=\"ts\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lineage_df[\"tree_length\"]**2) / np.sum(lineage_df[\"tree_length\"]) * 1.5 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Choose a rolling window size (adjust based on your data):\n",
    "window_size = 40\n",
    "\n",
    "# Sort the DataFrame by stage so that rolling is done in the correct order:\n",
    "lcp_df = lcp_df.sort_values(\"stage\")\n",
    "\n",
    "# Group by \"data type\" and compute rolling mean and std.\n",
    "# Using min_periods=1 so that we still get values at the beginning.\n",
    "df_trend = lcp_df.groupby(\"data type\").apply(\n",
    "    lambda x: x.assign(\n",
    "        moving_avg=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).mean(),\n",
    "        moving_std=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).std()\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Use a defined color sequence from Plotly and build a mapping (you could also use a custom dictionary).\n",
    "color_sequence = px.colors.qualitative.Plotly\n",
    "unique_types = sorted(lcp_df[\"data type\"].unique())  # sort for consistency\n",
    "color_map = {dt: color for dt, color in zip(unique_types, color_sequence)}\n",
    "# Alternatively, you can pass a discrete map directly when calling px.scatter:\n",
    "fig = go.Figure()\n",
    "# px.scatter(\n",
    "#     lcp_df, \n",
    "#     x=\"stage\", \n",
    "#     y=\"n_lcp_cells\", \n",
    "#     color=\"data type\", \n",
    "#     color_discrete_map=color_map,\n",
    "#     opacity=0.5\n",
    "# )\n",
    "\n",
    "fig = format_2d_plotly(fig, axis_labels=axis_labels, font_size=18)\n",
    "\n",
    "# Calculate moving average and std (using a rolling window)\n",
    "lcp_df_sorted = lcp_df.sort_values(\"stage\")\n",
    "df_trend = lcp_df_sorted.groupby(\"data type\").apply(\n",
    "    lambda x: x.assign(\n",
    "        moving_avg=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).mean(),\n",
    "        moving_std=x[\"n_lcp_cells\"].rolling(window=window_size, center=True, min_periods=1).std()\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Utility: Convert HEX color to RGBA (for the translucent fill)\n",
    "def hex_to_rgba(hex_color, alpha=0.2):\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return f\"rgba({r},{g},{b},{alpha})\"\n",
    "\n",
    "# Add traces for each data type: trendline and shaded error band.\n",
    "for dt in unique_types:\n",
    "    df_sub = df_trend[df_trend[\"data type\"] == dt].copy()\n",
    "    # Get the color for this group from our mapping:\n",
    "    base_color = color_map[dt]\n",
    "    \n",
    "    # Add trendline (moving average) trace:\n",
    "    avg_trace = go.Scatter(\n",
    "        x=df_sub[\"stage\"],\n",
    "        y=df_sub[\"moving_avg\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"{dt}\",\n",
    "        line=dict(color=base_color, width=3)\n",
    "    )\n",
    "    fig.add_trace(avg_trace)\n",
    "\n",
    "    # Calculate upper and lower bounds:\n",
    "    upper_bound = df_sub[\"moving_avg\"] + df_sub[\"moving_std\"]\n",
    "    lower_bound = df_sub[\"moving_avg\"] - df_sub[\"moving_std\"]\n",
    "\n",
    "    # Create a translucent shaded region for ±1 standard deviation:\n",
    "    error_band_trace = go.Scatter(\n",
    "        x=np.concatenate([df_sub[\"stage\"].to_numpy(), df_sub[\"stage\"].to_numpy()[::-1]]),\n",
    "        y=np.concatenate([upper_bound.to_numpy(), lower_bound.to_numpy()[::-1]]),\n",
    "        fill=\"toself\",\n",
    "        fillcolor=hex_to_rgba(base_color, alpha=0.4),\n",
    "        line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "        name=f\"{dt} ±1 SD\"\n",
    "    )\n",
    "    fig.add_trace(error_band_trace)\n",
    "\n",
    "# Format the axes if desired (using your custom formatting function, for example):\n",
    "axis_labels = [\"stage (hpf)\", \"number of detected lcp+ cells\"]\n",
    "# Assuming format_2d_plotly is your custom function:\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(fig_path + \"n_lcp_cells_vs_stage.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments look shite. What about the raw masks?\n",
    "Manual inspection indicates that a number of raw masks corresponding to lcp+ nuclei are beingd dropped durring tracking, which is frustrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "fluo_path = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_df_path_list = sorted(glob(fluo_path + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for fluo_p in tqdm(fluo_df_path_list):\n",
    "    df = pd.read_csv(fluo_p)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df = pd.concat(fluo_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(fluo_df[\"mean_fluo\"]>fluo_thresh))\n",
    "print(np.sum(tracks_df[\"mean_fluo\"]>fluo_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see substantially more high-fluo frames. Let's look at trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50  # for example\n",
    "\n",
    "# Group by time 't' and, for each group, pick the N rows with the highest 'mean_fluo'\n",
    "top_fluo_df = fluo_df.groupby('frame', group_keys=False).apply(lambda x: x.nlargest(N, columns='mean_fluo')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(top_fluo_df, x=\"frame\", y=\"mean_fluo\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi, fc = np.unique(fluo_df.loc[fluo_df[\"mean_fluo\"]>fluo_thresh, \"frame\"], return_counts=True)\n",
    "\n",
    "fig = px.scatter(x=fi, y=fc)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we're losing a ton during the tracking process. Sad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

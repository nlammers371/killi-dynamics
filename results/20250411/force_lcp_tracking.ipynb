{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T23:51:43.083885200Z",
     "start_time": "2025-04-14T23:51:31.043897600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from src.utilities.plot_functions import format_2d_plotly\n",
    "from ultrack.tracks.graph import get_paths_to_roots, tracks_df_forest, inv_tracks_df_forest\n",
    "from glob2 import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultrack may not want to track lcp+ cells, but by god we're going to make it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T23:51:51.938733500Z",
     "start_time": "2025-04-14T23:51:43.085885500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2339/2339 [00:08<00:00, 278.67it/s]\n"
     ]
    }
   ],
   "source": [
    "root = \"E:\\\\Nick\\\\Cole Trapnell's Lab Dropbox\\\\Nick Lammers\\\\Nick\\\\killi_tracker\\\\\"\n",
    "project_name = \"20250311_LCP1-NLSMSC\"\n",
    "\n",
    "# full mask dataset\n",
    "full_mask_fluo_dir = os.path.join(root, \"built_data\", \"fluorescence_data\", project_name, \"\")\n",
    "fluo_frames = sorted(glob(full_mask_fluo_dir + \"*.csv\"))\n",
    "fluo_df_list = []\n",
    "for df_path in tqdm(fluo_frames):\n",
    "    df = pd.read_csv(df_path)\n",
    "    fluo_df_list.append(df)\n",
    "\n",
    "fluo_df_full = pd.concat(fluo_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T23:51:51.999732700Z",
     "start_time": "2025-04-14T23:51:51.939734400Z"
    }
   },
   "outputs": [],
   "source": [
    "fluo_df_full[\"stage\"] = 26 + fluo_df_full[\"frame\"]*1.5/60\n",
    "fig_path = os.path.join(root, \"figures\", \"tracking\", project_name)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for only nuclei with bright lcp expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T00:14:49.267703300Z",
     "start_time": "2025-04-15T00:14:48.430655600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlammers\\AppData\\Local\\Temp\\ipykernel_14800\\3450884418.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  fluo_df_lcp = fluo_df_full.loc[fluo_df_full[\"stage\"]>=min_time, :].groupby('frame', group_keys=False).apply(lambda g: g.nlargest(N, 'mean_fluo'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "         nucleus_id  frame            z           y            x   mean_fluo  \\\n2266909          52   1760   205.821429  546.142857   505.750000  230.285720   \n2267085         228   1760   298.156250  517.333333   265.791667  128.937500   \n2267456         599   1760   480.352941  575.849612  1086.505549  107.199776   \n2268485        1628   1760  1071.911814  881.259013   840.084859  106.377700   \n2267270         413   1760   394.509150  768.526014  1001.585217  105.035880   \n\n         stage  \n2266909   70.0  \n2267085   70.0  \n2267456   70.0  \n2268485   70.0  \n2267270   70.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nucleus_id</th>\n      <th>frame</th>\n      <th>z</th>\n      <th>y</th>\n      <th>x</th>\n      <th>mean_fluo</th>\n      <th>stage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2266909</th>\n      <td>52</td>\n      <td>1760</td>\n      <td>205.821429</td>\n      <td>546.142857</td>\n      <td>505.750000</td>\n      <td>230.285720</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>2267085</th>\n      <td>228</td>\n      <td>1760</td>\n      <td>298.156250</td>\n      <td>517.333333</td>\n      <td>265.791667</td>\n      <td>128.937500</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>2267456</th>\n      <td>599</td>\n      <td>1760</td>\n      <td>480.352941</td>\n      <td>575.849612</td>\n      <td>1086.505549</td>\n      <td>107.199776</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>2268485</th>\n      <td>1628</td>\n      <td>1760</td>\n      <td>1071.911814</td>\n      <td>881.259013</td>\n      <td>840.084859</td>\n      <td>106.377700</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>2267270</th>\n      <td>413</td>\n      <td>1760</td>\n      <td>394.509150</td>\n      <td>768.526014</td>\n      <td>1001.585217</td>\n      <td>105.035880</td>\n      <td>70.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# fluo_thresh = 110\n",
    "min_time = 70 # avoid weird early stuff\n",
    "N = 50\n",
    "# fluo_df_lcp = fluo_df_full.loc[(fluo_df_full[\"mean_fluo\"]>fluo_thresh) & (fluo_df_full[\"stage\"]>min_time), :].copy()\n",
    "fluo_df_lcp = fluo_df_full.loc[fluo_df_full[\"stage\"]>=min_time, :].groupby('frame', group_keys=False).apply(lambda g: g.nlargest(N, 'mean_fluo'))\n",
    "fluo_df_lcp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Call track stitching...can we use this to track single-frame fragments?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlammers\\AppData\\Local\\Temp\\ipykernel_14800\\2657394084.py:2: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  tracks_df['id'] = pd.factorize(list(zip(tracks_df['t'], tracks_df['nucleus_id'])))[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(28950, 9)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df = fluo_df_lcp.rename(columns={\"frame\": \"t\"}).sort_values(by=[\"t\", \"nucleus_id\"])\n",
    "tracks_df['id'] = pd.factorize(list(zip(tracks_df['t'], tracks_df['nucleus_id'])))[0]\n",
    "tracks_df[\"parent_track_id\"] = -1\n",
    "tracks_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T00:14:51.754611500Z",
     "start_time": "2025-04-15T00:14:51.722611500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 578/578 [00:00<00:00, 1162.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from ultrack.tracks.gap_closing import close_tracks_gaps\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "max_radius = 25\n",
    "scale_vec = np.asarray([3, 1, 1])\n",
    "time_index = np.unique(tracks_df[\"t\"])\n",
    "tracks_df[\"track_id\"] = -1\n",
    "# Split the DataFrame by the unique values in the 'group' column\n",
    "dfs = {key: group for key, group in tracks_df.groupby('t')}\n",
    "dfs[time_index[0]][\"track_id\"] = np.arange(dfs[time_index[0]].shape[0])\n",
    "\n",
    "# perform cell tracking\n",
    "for _, t1 in enumerate(tqdm(time_index[1:])):\n",
    "\n",
    "    # get prev locations and IDs\n",
    "    df0 = dfs[t1-1]\n",
    "    xyz0 = np.multiply(df0[[\"x\", \"y\", \"z\"]].to_numpy(), scale_vec)\n",
    "    extant_tracks = df0[\"track_id\"].to_numpy()\n",
    "    # get curr locations\n",
    "    df1 = dfs[t1]\n",
    "    xyz1 = np.multiply(df1[[\"x\", \"y\", \"z\"]].to_numpy(), scale_vec)\n",
    "\n",
    "    # get distances\n",
    "    dist_mat = distance_matrix(xyz1, xyz0)\n",
    "\n",
    "    # solve\n",
    "    row_ind, col_ind = linear_sum_assignment(dist_mat)\n",
    "\n",
    "    # assign track IDs\n",
    "    valid_links = dist_mat[row_ind, col_ind] < max_radius\n",
    "\n",
    "    new_track_ids = np.zeros_like(extant_tracks) - 1\n",
    "    new_track_ids[valid_links] = extant_tracks[col_ind[valid_links]]\n",
    "\n",
    "    # assign new track IDs\n",
    "    max_id = np.max(extant_tracks)\n",
    "    n_new = np.sum(~valid_links)\n",
    "    new_track_ids[~valid_links] = np.arange(max_id+1, max_id+n_new+1)\n",
    "\n",
    "    # assign to dataframe\n",
    "    df1[\"track_id\"] = new_track_ids\n",
    "    # assign to dictionary\n",
    "    dfs[t1] = df1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T00:14:55.803619400Z",
     "start_time": "2025-04-15T00:14:55.274596800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "6018"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dict to dataframe\n",
    "tracks_df = pd.concat(dfs.values(), axis=0, ignore_index=True)\n",
    "len(np.unique(tracks_df[\"track_id\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T00:14:57.263838900Z",
     "start_time": "2025-04-15T00:14:57.223839800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching tracks...\n"
     ]
    }
   ],
   "source": [
    "# do stitching\n",
    "print(\"Stitching tracks...\")\n",
    "max_gap = 3\n",
    "max_radius = 25 * 3\n",
    "scale_vec = np.array([3, 1, 1])\n",
    "tracks_df_stitched = close_tracks_gaps(tracks_df, max_gap=max_gap, max_radius=max_radius, scale=scale_vec)\n",
    "\n",
    "# make save path\n",
    "data_path = os.path.join(root, \"built_data\", \"tracking\", project_name)\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "tracks_df_stitched.to_csv(os.path.join(data_path, \"lcp_tracks_df.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T00:15:47.396867500Z",
     "start_time": "2025-04-15T00:15:32.153821400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "3382"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(tracks_df_stitched[\"track_id\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T00:15:49.755736200Z",
     "start_time": "2025-04-15T00:15:49.740736100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
